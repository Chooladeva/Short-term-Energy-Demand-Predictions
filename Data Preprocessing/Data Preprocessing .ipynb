{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a4bcbc5-89c1-4d9b-b009-287f30dc1921",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1> </font> <font color = #4854E8>Data Preprocessing</h2> </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe8a12d-5832-4058-aeeb-7ebc3bfa1bd1",
   "metadata": {},
   "source": [
    "> The data preprocessing stage included cleaning the data to remove any inconsistencies or errors, dealing with missing data using imputation, and handling outliers that might skew the results through the \"capping\" method. Furthermore, temporal and seasonal parameters were developed to capture the time-dependent patterns in the data, and weather-related features were retrieved to incorporate climatic impacts on energy demand. Moreover, trends and seasonality were removed from the target variable in order to effectively isolate the underlying patterns. Categorical variables were encoded to incorporate them in machine learning models, and the data were resampled at an hourly frequency for consistency and ease of analysis. To carry out these preparation steps, several Python tools were used, including Pandas for data manipulation, NumPy for numerical operations, and Scikit-Learn for categorical variable encoding. Additionally, the Statsmodels library was used for seasonal decomposition analysis to identify seasonal components in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8240d6-abf1-4fa0-8aa9-164fe1ddd6ff",
   "metadata": {},
   "source": [
    "**The data obtained from the Bureau of Meteorology (BOM) automatic weather stations in Australia, which provide half-hourly temperature measurements spanning two decades in the capital cities of Hobart, Melbourne, Adelaide, Sydney, and Brisbane. And half-hourly energy demand measurements across five states: South Australia, Victoria, New South Wales, Queensland, and Tasmania.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b4961",
   "metadata": {},
   "source": [
    "# 01- Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5960b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a17fe5",
   "metadata": {},
   "source": [
    "# 02- Importing datasets\n",
    "\n",
    "There are many temperature and energy spreadsheets formatted as CSVs. Although there's an incredible number of them, it is just because the data was divided into small chunks. Each CSV is a continuation of the last one. The temperature spreadsheets contain dates, along with a variety of temperature, humidity and precipitation measurements.The energy files contain dates, energy demand history, prices (RRP) and whether the data was manually or automatically logged. The measurements have been made on a 30-minute basis.\n",
    "\n",
    "Following code reads those multiple CSV files from specified directories, creates Pandas DataFrames for each CSV file, and then concatenates these DataFrames into two main DataFrames (energy and temperature). These DataFrames contain the combined data from all the CSV files, for further analysis and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1409349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the directories containing the CSV files\n",
    "data_directory = \"C:/Users/HP/Documents/NIBM/Year 3/Research Project/1- My Project Report/Model Training and Prediction/Data\"\n",
    "\n",
    "# Retrieve a list of filenames present in the energy and temperature directories\n",
    "energy_directory = os.path.join(data_directory, \"Energy\")\n",
    "temperature_directory = os.path.join(data_directory, \"Temperature\")\n",
    "\n",
    "energy_locations = os.listdir(energy_directory)\n",
    "temperature_locations = os.listdir(temperature_directory)\n",
    "\n",
    "# Read each CSV file present in the Energy directory and create a list of DataFrames\n",
    "energy_CSVs = [pd.read_csv(os.path.join(energy_directory, location)) for location in energy_locations]\n",
    "\n",
    "# Read each CSV file present in the Temperature directory (only files containing \"Data\" in their filename) and create a list of DataFrames\n",
    "temperature_CSVs = [pd.read_csv(os.path.join(temperature_directory, location)) for location in temperature_locations if \"Data\" in location]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa1de141",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = pd.concat(energy_CSVs, ignore_index=True)\n",
    "temperature = pd.concat(temperature_CSVs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7fd0350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['REGION', 'SETTLEMENTDATE', 'TOTALDEMAND', 'RRP', 'PERIODTYPE'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Index(['hm', 'Station Number', 'Year Month Day Hour Minutes in YYYY', 'MM',\n",
       "       'DD', 'HH24', 'MI format in Local time',\n",
       "       'Year Month Day Hour Minutes in YYYY.1', 'MM.1', 'DD.1', 'HH24.1',\n",
       "       'MI format in Local standard time',\n",
       "       'Precipitation since 9am local time in mm',\n",
       "       'Quality of precipitation since 9am local time',\n",
       "       'Air Temperature in degrees C', 'Quality of air temperature',\n",
       "       'Wet bulb temperature in degrees C', 'Quality of Wet bulb temperature',\n",
       "       'Dew point temperature in degrees C',\n",
       "       'Quality of dew point temperature', 'Relative humidity in percentage %',\n",
       "       'Quality of relative humidity', 'Wind speed in km/h',\n",
       "       'Wind speed quality', 'Wind direction in degrees true',\n",
       "       'Wind direction quality',\n",
       "       'Speed of maximum windgust in last 10 minutes in  km/h',\n",
       "       'Quality of speed of maximum windgust in last 10 minutes',\n",
       "       'Mean sea level pressure in hPa', 'Quality of mean sea level pressure',\n",
       "       'Station level pressure in hPa', 'Quality of station level pressure',\n",
       "       'AWS Flag', '#'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy.columns\n",
    "temperature.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff456d9",
   "metadata": {},
   "source": [
    "# 03- Preprocessing the energy and temperature data by cleaning, transforming, and structuring \n",
    "\n",
    "The following data cleaning steps defines two functions, preprocess_energy and preprocess_temperature, which perform data preprocessing tasks on Pandas DataFrames representing energy and temperature data respectively.\n",
    "\n",
    "- For energy data, the function renames columns, removes columns with mostly constant values, drops duplicate rows, maps region codes to their corresponding names, converts date strings to datetime objects, sets the datetime column as the index, and removes the 'RRP' column.\n",
    "\n",
    "- For temperature data, the function renames columns, removes columns with mostly constant values, drops duplicate rows, drops unnecessary columns, maps station numbers to region names, converts date components to a datetime object, replaces \"###\" values in the 'RelativeHumidity%' column with NaN, strips leading and trailing whitespaces from numeric columns, converts numeric columns to numeric data types, and sets the datetime column as the index. Finally, the relevant time-related columns such as 'Year', 'Month', 'Day', 'Hour', and 'Minute' are converted to integer data types to conserve memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dab6e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_energy(energy):\n",
    "    \n",
    "    # Identify columns with two or fewer unique values (mostly constant) and remove them\n",
    "    remove_energy = [name for name, series in energy.items() if len(series.unique()) <= 2]\n",
    "    energy.drop(remove_energy, axis=1, inplace=True)\n",
    "    \n",
    "    # Drop duplicate rows\n",
    "    energy.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    energy.drop([\"RRP\"], axis=1, inplace=True)\n",
    "    \n",
    "    # Rename columns\n",
    "    energy.columns = [\"Region\", \"Date\", \"TotalDemand\"]\n",
    "    \n",
    "    # Rename Region\n",
    "    region_remove_number_map = {\"SA1\": \"SA\", \"QLD1\": \"QLD\", \"NSW1\": \"NSW\", \"VIC1\": \"VIC\", \"TAS1\": \"TAS\"}\n",
    "    energy[\"Region\"] = energy[\"Region\"].map(region_remove_number_map)\n",
    "    \n",
    "    # Convert Region column to categorical data type\n",
    "    energy['Region'] = pd.Categorical(energy['Region'])\n",
    "    \n",
    "    # Convert 'Date' column to the aatetime format\n",
    "    energy[\"Date\"] = pd.to_datetime(energy[\"Date\"])\n",
    "    \n",
    "    # Set 'Date' column as index\n",
    "    energy.set_index(\"Date\", inplace=True)\n",
    "    \n",
    "    \n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "152f4064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>TotalDemand</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:30:00</th>\n",
       "      <td>NSW</td>\n",
       "      <td>6763.57000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 01:00:00</th>\n",
       "      <td>NSW</td>\n",
       "      <td>6386.10167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 01:30:00</th>\n",
       "      <td>NSW</td>\n",
       "      <td>5990.79500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 02:00:00</th>\n",
       "      <td>NSW</td>\n",
       "      <td>5655.97667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 02:30:00</th>\n",
       "      <td>NSW</td>\n",
       "      <td>5283.83667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 22:00:00</th>\n",
       "      <td>VIC</td>\n",
       "      <td>4129.96000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 22:30:00</th>\n",
       "      <td>VIC</td>\n",
       "      <td>4083.66000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:00:00</th>\n",
       "      <td>VIC</td>\n",
       "      <td>4104.95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:30:00</th>\n",
       "      <td>VIC</td>\n",
       "      <td>4325.88000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>VIC</td>\n",
       "      <td>4372.27000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1658965 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Region  TotalDemand\n",
       "Date                                   \n",
       "2000-01-01 00:30:00    NSW   6763.57000\n",
       "2000-01-01 01:00:00    NSW   6386.10167\n",
       "2000-01-01 01:30:00    NSW   5990.79500\n",
       "2000-01-01 02:00:00    NSW   5655.97667\n",
       "2000-01-01 02:30:00    NSW   5283.83667\n",
       "...                    ...          ...\n",
       "2019-12-31 22:00:00    VIC   4129.96000\n",
       "2019-12-31 22:30:00    VIC   4083.66000\n",
       "2019-12-31 23:00:00    VIC   4104.95000\n",
       "2019-12-31 23:30:00    VIC   4325.88000\n",
       "2020-01-01 00:00:00    VIC   4372.27000\n",
       "\n",
       "[1658965 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_data = preprocess_energy(energy)\n",
    "energy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "133b1a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_temperature(temperature):\n",
    "    \n",
    "    # Rename columns\n",
    "    temperature.columns = [\n",
    "        \"HM\", \"StationNumber\", \"Year1\", \"Month1\", \"Day1\", \"Hour1\", \"Minute1\", \"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\", \"Precipitation\", \"PrecipitationQuality\",\n",
    "        \"AirTemperature\", \"AirTemperatureQuality\", \"WetBulbTemperature\", \"WetBulbTemperatureQuality\", \"DewTemperature\", \"DewTemperatureQuality\", \"RelativeHumidity%\",\n",
    "        \"RelativeHumidityQuality\", \"WindSpeed\", \"WindSpeedQuality\", \"WindDirection\", \"WindDirectionQuality\", \"WindgustSpeed\", \"WindgustSpeedQuality\", \"SeaPressure\",\n",
    "        \"SeaPressureQuality\", \"StationPressure\", \"StationPressureQuality\", \"AWSFlag\", \"#\"\n",
    "    ]\n",
    "    \n",
    "    # Identify columns with two or fewer unique values (mostly constant) and remove them\n",
    "    remove_temperature = [name for name, series in temperature.items() if len(series.unique()) <= 2]\n",
    "    temperature.drop(remove_temperature, axis=1, inplace=True)\n",
    "\n",
    "    # Drop duplicate rows\n",
    "    temperature.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    temperature.drop([\"Year1\", \"Month1\", \"Day1\", \"Hour1\", \"Minute1\"], axis=1, inplace=True)\n",
    "    temperature.drop([\"AWSFlag\"], axis=1, inplace=True)\n",
    "    \n",
    "    # Convert to datetime and create a 'Date' column\n",
    "    temperature[\"Date\"] = pd.to_datetime(temperature[[\"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\"]])\n",
    "\n",
    "    # Map StationNumber to Region\n",
    "    station_to_region_map = {23090: \"SA\", 40913: \"QLD\", 66062: \"NSW\", 86071: \"VIC\", 94029: \"TAS\", 86338: \"VIC\"}\n",
    "    temperature[\"Region\"] = temperature[\"StationNumber\"].map(station_to_region_map)\n",
    "    temperature.drop(\"StationNumber\", axis=1, inplace=True)\n",
    "\n",
    "    # Replace \"###\" in RelativeHumidity with NaN\n",
    "    temperature[\"RelativeHumidity%\"] = temperature[\"RelativeHumidity%\"].replace(\"###\", np.NaN)\n",
    "\n",
    "    # Dealing with leading and trailing white spaces in numeric columns\n",
    "    numeric_columns = ['Precipitation', 'AirTemperature', 'WetBulbTemperature', 'DewTemperature',\n",
    "                        'RelativeHumidity%', 'WindSpeed', 'WindDirection', 'WindgustSpeed',\n",
    "                        'SeaPressure', 'StationPressure']\n",
    "    for column in numeric_columns:\n",
    "        temperature[column] = temperature[column].str.strip()\n",
    "        temperature[column] = pd.to_numeric(temperature[column], errors='coerce')\n",
    "        \n",
    "    # Set 'Date' column as index\n",
    "    temperature.set_index(\"Date\", inplace=True)\n",
    "    \n",
    "    # Convert Region column to categorical data type\n",
    "    temperature['Region'] = pd.Categorical(temperature['Region'])\n",
    "    \n",
    "    return temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7024e9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>AirTemperature</th>\n",
       "      <th>WetBulbTemperature</th>\n",
       "      <th>DewTemperature</th>\n",
       "      <th>RelativeHumidity%</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindDirection</th>\n",
       "      <th>WindgustSpeed</th>\n",
       "      <th>SeaPressure</th>\n",
       "      <th>StationPressure</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:00</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>1018.9</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:30:00</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>1018.7</td>\n",
       "      <td>1012.6</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 01:00:00</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.4</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>1018.5</td>\n",
       "      <td>1012.4</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 01:30:00</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>1012.2</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 02:00:00</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>1012.2</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-20 07:00:00</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1005.3</td>\n",
       "      <td>TAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-20 07:30:00</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1005.4</td>\n",
       "      <td>TAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-20 08:00:00</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>TAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-20 08:30:00</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>22.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1005.5</td>\n",
       "      <td>TAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-20 09:00:00</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>TAS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826244 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Year  Month  Day  Hour  Minute  Precipitation  \\\n",
       "Date                                                                 \n",
       "2000-01-01 00:00:00  2000      1    1     0       0            NaN   \n",
       "2000-01-01 00:30:00  2000      1    1     0      30            NaN   \n",
       "2000-01-01 01:00:00  2000      1    1     1       0            NaN   \n",
       "2000-01-01 01:30:00  2000      1    1     1      30            NaN   \n",
       "2000-01-01 02:00:00  2000      1    1     2       0            NaN   \n",
       "...                   ...    ...  ...   ...     ...            ...   \n",
       "2020-01-20 07:00:00  2020      1   20     7       0            0.0   \n",
       "2020-01-20 07:30:00  2020      1   20     7      30            0.0   \n",
       "2020-01-20 08:00:00  2020      1   20     8       0            0.0   \n",
       "2020-01-20 08:30:00  2020      1   20     8      30            0.0   \n",
       "2020-01-20 09:00:00  2020      1   20     9       0            0.0   \n",
       "\n",
       "                     AirTemperature  WetBulbTemperature  DewTemperature  \\\n",
       "Date                                                                      \n",
       "2000-01-01 00:00:00            13.1                10.0             6.6   \n",
       "2000-01-01 00:30:00            13.2                10.1             6.8   \n",
       "2000-01-01 01:00:00            13.4                10.1             6.5   \n",
       "2000-01-01 01:30:00            13.2                10.0             6.5   \n",
       "2000-01-01 02:00:00            13.0                 9.7             6.0   \n",
       "...                             ...                 ...             ...   \n",
       "2020-01-20 07:00:00             NaN                12.5             NaN   \n",
       "2020-01-20 07:30:00             NaN                12.4             NaN   \n",
       "2020-01-20 08:00:00             NaN                12.4             NaN   \n",
       "2020-01-20 08:30:00             NaN                12.4             NaN   \n",
       "2020-01-20 09:00:00             NaN                12.6             NaN   \n",
       "\n",
       "                     RelativeHumidity%  WindSpeed  WindDirection  \\\n",
       "Date                                                               \n",
       "2000-01-01 00:00:00               65.0        NaN          190.0   \n",
       "2000-01-01 00:30:00               65.0        NaN          200.0   \n",
       "2000-01-01 01:00:00               63.0        NaN          180.0   \n",
       "2000-01-01 01:30:00               64.0        NaN          170.0   \n",
       "2000-01-01 02:00:00               62.0        NaN          150.0   \n",
       "...                                ...        ...            ...   \n",
       "2020-01-20 07:00:00                NaN        NaN          130.0   \n",
       "2020-01-20 07:30:00                NaN        NaN          140.0   \n",
       "2020-01-20 08:00:00                NaN        NaN          150.0   \n",
       "2020-01-20 08:30:00                NaN        NaN          150.0   \n",
       "2020-01-20 09:00:00                NaN        NaN          170.0   \n",
       "\n",
       "                     WindgustSpeed  SeaPressure  StationPressure Region  \n",
       "Date                                                                     \n",
       "2000-01-01 00:00:00           24.1       1018.9           1012.8     SA  \n",
       "2000-01-01 00:30:00           16.6       1018.7           1012.6     SA  \n",
       "2000-01-01 01:00:00           20.5       1018.5           1012.4     SA  \n",
       "2000-01-01 01:30:00           18.4       1018.3           1012.2     SA  \n",
       "2000-01-01 02:00:00           20.5       1018.3           1012.2     SA  \n",
       "...                            ...          ...              ...    ...  \n",
       "2020-01-20 07:00:00           20.5          NaN           1005.3    TAS  \n",
       "2020-01-20 07:30:00           18.4          NaN           1005.4    TAS  \n",
       "2020-01-20 08:00:00           24.1          NaN           1005.6    TAS  \n",
       "2020-01-20 08:30:00           22.3          NaN           1005.5    TAS  \n",
       "2020-01-20 09:00:00           25.9          NaN           1005.0    TAS  \n",
       "\n",
       "[1826244 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_data = preprocess_temperature(temperature)\n",
    "temperature_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee8373f",
   "metadata": {},
   "source": [
    "##  Calculating upper and lower bounds before the na values imputation\n",
    "\n",
    "The following code groups weather data by region and computes the lower and upper bounds for outlier detection using the Interquartile Range (IQR) method for five different weather-related variables: AirTemperature, WetBulbTemperature, DewTemperature, SeaPressure, and StationPressure. It defines a function to calculate these bounds based on the IQR formula, then applies this function to each column separately for each region. The resulting bounds are stored in separate variables, providing a clear understanding of the data distribution and potential outliers before any data imputation or modification occurs. These bounds serve as valuable insights for quality control and anomaly detection in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5c2bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by \"Region\"\n",
    "grouped_data = temperature_data.groupby('Region')\n",
    "\n",
    "# Define a function to calculate lower and upper bounds for a specific column\n",
    "def calculate_bounds(group, column_name):\n",
    "    Q1 = group[column_name].quantile(0.25)\n",
    "    Q3 = group[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Apply the function to each column separately and store the results in separate variables\n",
    "AirTemperature_bounds_before_imputation = grouped_data.apply(calculate_bounds, column_name='AirTemperature')\n",
    "WetBulbTemperature_bounds_before_imputation = grouped_data.apply(calculate_bounds, column_name='WetBulbTemperature')\n",
    "DewTemperature_bounds_before_imputation = grouped_data.apply(calculate_bounds, column_name='DewTemperature')\n",
    "SeaPressure_bounds_before_imputation = grouped_data.apply(calculate_bounds, column_name='SeaPressure')\n",
    "StationPressure_bounds_before_imputation = grouped_data.apply(calculate_bounds, column_name='StationPressure')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1bcaae",
   "metadata": {},
   "source": [
    "# 04- Dealing with missing data\n",
    "\n",
    "The following function is designed to address missing data within the temperature_data DataFrame, particularly focusing on interpolation and replacement strategies. It first identifies columns with missing values by calculating the percentage of null values for each column. These columns are then selected for interpolation using the \"time\" method, which fills missing values by linearly interpolating based on time. Additionally, missing values in the 'Precipitation' column are filled with 0, presumably indicating no precipitation when data is missing. Furthermore, certain columns ('WindSpeed', 'WindDirection', and 'WindgustSpeed') are deemed unnecessary and are consequently removed from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7108e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(temperature_data):\n",
    "    \n",
    "    # Calculate the percentage of null values for each column\n",
    "    missing_columns = temperature_data.isnull().mean()[temperature_data.isnull().mean() > 0].keys()\n",
    "\n",
    "    # Interpolate missing values in the identified columns using the \"time\" method\n",
    "    temperature_data[missing_columns] = temperature_data[missing_columns].interpolate(method=\"time\")\n",
    "\n",
    "    # Replace remaining null values in the 'Precipitation' column with 0\n",
    "    temperature_data['Precipitation'].fillna(0, inplace=True)\n",
    "    \n",
    "    remove_columns = [\"WindSpeed\", \"WindDirection\", \"WindgustSpeed\"]\n",
    "    temperature_data.drop(remove_columns, axis=1, inplace=True)\n",
    "\n",
    "    return temperature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "460d399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_data = impute_missing_values(temperature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a7aeba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "missing_values = temperature_data.isnull().sum()\n",
    "\n",
    "# Display the columns with missing values\n",
    "print(\"Columns with missing values:\")\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf70a38",
   "metadata": {},
   "source": [
    "# 05- Dealing with outliers\n",
    "\n",
    "When dealing with outliers, I utilized Outlier capping method, also known as winsorization or trimming, is a method used to handle extreme values (outliers) in a dataset. Outliers are data points that deviate significantly from the rest of the data, potentially skewing statistical analyses or machine learning models. Capping involves setting a threshold beyond which values are adjusted to be equal to the threshold.\n",
    "\n",
    "The following function cap_outliers defines that for a specific region and column based on above pre-defined bounds. It then applies this function to each row in the DataFrame temperature_data for various temperature-related columns like 'AirTemperature', 'WetBulbTemperature', 'DewTemperature', and pressure-related columns like 'SeaPressure', 'StationPressure'. The outlier capping is performed separately for each column, considering the region specified in the DataFrame. For each region, it compares the imputed values to the bounds calculated before imputation. If an imputed value falls outside the corresponding bounds, replace it with the nearest bound. After capping, the original columns are dropped, and the capped columns are renamed to replace the original ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d03317cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to cap outliers for a specific region and column using bounds before imputation\n",
    "def cap_outliers(region, value, bounds):\n",
    "    lower_bound, upper_bound = bounds[region]\n",
    "    if value < lower_bound:\n",
    "        return lower_bound\n",
    "    elif value > upper_bound:\n",
    "        return upper_bound\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "# Apply capping to each row in the DataFrame for each column separately using bounds before imputation\n",
    "temperature_data['Capped_AirTemperature'] = temperature_data.apply(lambda row: cap_outliers(row['Region'], row['AirTemperature'], AirTemperature_bounds_before_imputation), axis=1)\n",
    "temperature_data['Capped_WetBulbTemperature'] = temperature_data.apply(lambda row: cap_outliers(row['Region'], row['WetBulbTemperature'], WetBulbTemperature_bounds_before_imputation), axis=1)\n",
    "temperature_data['Capped_DewTemperature'] = temperature_data.apply(lambda row: cap_outliers(row['Region'], row['DewTemperature'], DewTemperature_bounds_before_imputation), axis=1)\n",
    "temperature_data['Capped_SeaPressure'] = temperature_data.apply(lambda row: cap_outliers(row['Region'], row['SeaPressure'], SeaPressure_bounds_before_imputation), axis=1)\n",
    "temperature_data['Capped_StationPressure'] = temperature_data.apply(lambda row: cap_outliers(row['Region'], row['StationPressure'], StationPressure_bounds_before_imputation), axis=1)\n",
    "\n",
    "# Drop the original columns\n",
    "temperature_data.drop(columns=['AirTemperature', 'WetBulbTemperature', 'DewTemperature', 'SeaPressure', 'StationPressure'], inplace=True)\n",
    "\n",
    "# Rename the capped columns\n",
    "temperature_data.rename(columns={'Capped_AirTemperature': 'AirTemperature', \n",
    "                                 'Capped_WetBulbTemperature': 'WetBulbTemperature', \n",
    "                                 'Capped_DewTemperature': 'DewTemperature', \n",
    "                                 'Capped_SeaPressure': 'SeaPressure', \n",
    "                                 'Capped_StationPressure': 'StationPressure'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c60d4e",
   "metadata": {},
   "source": [
    "# 06- Generating Temporal and Seasonal related Parameters\n",
    "The following function improves the temperature_data DataFrame by deriving several time-related features from its datetime index. Initially, it captures the day of the week, week of the month, quarter of the year, and day of the year, providing granularity in understanding temperature variations over time. Additionally, it maps each month to its corresponding season, facilitating the exploration of seasonal trends. Furthermore, it categorizes observations into distinct time periods such as night, morning, afternoon, and evening, offering insights into diurnal temperature patterns. The function also generates binary indicators for weekends, seasons (summer and winter), daytime, and holidays, enabling the identification of temporal patterns and anomalies in temperature data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c0728ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_related_features(temperature_data):\n",
    "    \n",
    "    # Extract the day of the week as names\n",
    "    temperature_data['DayOfWeek'] = temperature_data.index.strftime('%A')\n",
    "    \n",
    "    # Calculate the week of the month \n",
    "    temperature_data['WeekOfMonth'] = (temperature_data.index.day - 1) // 7 + 1\n",
    "    \n",
    "    # Extract the quarter of the year \n",
    "    temperature_data['Quarter'] = temperature_data.index.quarter\n",
    "    \n",
    "    # Extract the day of the month\n",
    "    temperature_data['DayOfYear'] = temperature_data.index.dayofyear\n",
    "    \n",
    "    # Map each month to a corresponding season\n",
    "    temperature_data['Season'] = temperature_data.index.month.map({\n",
    "        1: 'Summer', 2: 'Summer', 3: 'Autumn',\n",
    "        4: 'Autumn', 5: 'Autumn', 6: 'Winter',\n",
    "        7: 'Winter', 8: 'Winter', 9: 'Spring',\n",
    "        10: 'Spring', 11: 'Spring', 12: 'Summer'\n",
    "    })\n",
    "    \n",
    "    # Apply the lambda function to create the TimeOfDay column \n",
    "    temperature_data['TimeOfDay'] = temperature_data['Hour'].apply(lambda hour: \n",
    "                                                              'Morning' if 5 <= hour < 12 \n",
    "                                                              else ('Afternoon' if 12 <= hour < 17 \n",
    "                                                                    else ('Evening' if 17 <= hour < 21 \n",
    "                                                                          else 'Night')))\n",
    "\n",
    "    # Create binary feature for weekends and weekdays\n",
    "    temperature_data['IsWeekend'] = (temperature_data['DayOfWeek'] == 'Saturday') | (temperature_data['DayOfWeek'] == 'Sunday')\n",
    "    \n",
    "    return temperature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c50797f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_data = get_time_related_features(temperature_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6119310c",
   "metadata": {},
   "source": [
    "# 07- Generating weather related features\n",
    "\n",
    "The following function enhances the temperature_data DataFrame by deriving a range of weather-related features, providing valuable insights into atmospheric conditions. First, it calculates the difference between air temperature and dew temperature, offering an indication of atmospheric moisture levels. Then, it computes the difference between sea pressure and station pressure, reflecting variations in atmospheric pressure. Additionally, it assesses the difference in air temperature between daytime and nighttime, capturing diurnal temperature fluctuations. Moreover, it categorizes air temperature, precipitation intensity, station pressure, and relative humidity into discrete levels, enabling to capture the potential non-linear effects between weather features and energy consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89367cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_related_features(temperature_data):\n",
    "    \n",
    "    # The difference between AirTemperature and DewTemperature\n",
    "    temperature_data['TemperatureDifference'] = temperature_data['AirTemperature'] - temperature_data['DewTemperature']\n",
    "    \n",
    "    # The difference between sea pressure and station pressure.\n",
    "    temperature_data['PressureDifference'] = temperature_data['SeaPressure'] - temperature_data['StationPressure']\n",
    "    \n",
    "    # Create a feature that represents the difference in air temperature between day and night.\n",
    "    day_avg_temp = temperature_data.loc[temperature_data['TimeOfDay'].isin(['Morning', 'Afternoon']), 'AirTemperature'].mean()\n",
    "    night_avg_temp = temperature_data.loc[temperature_data['TimeOfDay'].isin(['Evening', 'Night']), 'AirTemperature'].mean()\n",
    "    DayNightTempDifference = day_avg_temp - night_avg_temp\n",
    "    temperature_data['DayNightTempDifference'] = DayNightTempDifference\n",
    "    \n",
    "    # categorical variable indicating the temperature levels\n",
    "    bins1=[-np.inf, 0, 10, 20, 30, np.inf]\n",
    "    temperature_levels = ['Very Cold', 'Cold', 'Mild', 'Warm', 'Hot']\n",
    "    temperature_data['TemperatureLevel'] = pd.cut(temperature_data['AirTemperature'], bins=bins1, labels=temperature_levels)\n",
    "    \n",
    "    # categorical variable indicating the intensity of precipitation\n",
    "    bins2=[-np.inf, 0, 8, 20, np.inf]\n",
    "    precipitation_levels = ['No Precipitation', 'Light Precipitation', 'Moderate Precipitation', 'Heavy Precipitation']\n",
    "    temperature_data['PrecipitationLevel'] = pd.cut(temperature_data['Precipitation'], bins=bins2, labels=precipitation_levels)\n",
    "    \n",
    "    # categorical variable indicating the pressure levels\n",
    "    bins3=[-np.inf, 1000, 1030, np.inf]\n",
    "    pressure_levels = ['Low Pressure', 'Normal Pressure', 'High Pressure']\n",
    "    temperature_data['PressureLevel'] = pd.cut(temperature_data['StationPressure'], bins=bins3, labels=pressure_levels)\n",
    "    \n",
    "    # create bins for relative humidity to categorize it into different levels, indicating the amount of moisture in the air\n",
    "    bins4 = [0, 30, 70, np.inf]\n",
    "    humidity_levels = ['Low Moist', 'Moderate Moist', 'High Moist']\n",
    "    temperature_data['HumidityLevel'] = pd.cut(temperature_data['RelativeHumidity%'], bins=bins4, labels=humidity_levels)\n",
    "    \n",
    "    # Convert float columns to float32\n",
    "    float_columns = ['TemperatureDifference', 'PressureDifference', 'DayNightTempDifference']\n",
    "    temperature_data[float_columns] = temperature_data[float_columns].astype(np.float32)\n",
    "    \n",
    "    return temperature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "364cbac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_data= get_weather_related_features(temperature_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fdfccd",
   "metadata": {},
   "source": [
    "# 08- Combining energy and temperature data\n",
    "\n",
    "Initially, the function sorts both the energy and temperature dataframes by their indices to ensure consistency. Subsequently, the pd.merge_asof function is employed to merge the two dataframes based on the shared column \"Region,\" effectively combining relevant information from both datasets. A tolerance of 30 minutes is specified to allow for small temporal differences between entries from the two datasets. To handle missing values in the merged dataframe, the interpolate method with the 'pad' option is applied, ensuring that missing values are filled based on the nearest non-missing values (forward fill). Finally, certain columns such as Year, Month, Day, and Hour are converted to appropriate integer data types (e.g., np.int16 and np.uint8) to optimize memory usage and ensure data consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "632e65e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_master_table(energy_data, temperature_data):\n",
    "    \n",
    "    # Sort dataframes by index\n",
    "    energy_data.sort_index(inplace=True)\n",
    "    temperature_data.sort_index(inplace=True)\n",
    "\n",
    "    # Merge dataframes using pd.merge_asof\n",
    "    master_table = pd.merge_asof(\n",
    "        energy_data, temperature_data, left_index=True, right_index=True, by=\"Region\", tolerance=pd.Timedelta(\"30 min\")\n",
    "    )\n",
    "\n",
    "    # Interpolate missing values using the nearest non-missing values (forward fill)\n",
    "    master_table = master_table.interpolate(method='pad')\n",
    "    \n",
    "    # Convert to appropriate integer data types\n",
    "    master_table['Year'] = master_table['Year'].astype(np.int16)\n",
    "    master_table['Month'] = master_table['Month'].astype(np.uint8)\n",
    "    master_table['Day'] = master_table['Day'].astype(np.uint8)\n",
    "    master_table['Hour'] = master_table['Hour'].astype(np.uint8)\n",
    "    master_table['WeekOfMonth'] = master_table['WeekOfMonth'].astype(np.uint8)\n",
    "    master_table['Quarter'] = master_table['Quarter'].astype(np.uint8)\n",
    "    master_table['DayOfYear'] = master_table['DayOfYear'].astype(np.uint16)\n",
    "\n",
    "    return master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ec90770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>TotalDemand</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>RelativeHumidity%</th>\n",
       "      <th>AirTemperature</th>\n",
       "      <th>WetBulbTemperature</th>\n",
       "      <th>DewTemperature</th>\n",
       "      <th>SeaPressure</th>\n",
       "      <th>StationPressure</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>WeekOfMonth</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>DayOfYear</th>\n",
       "      <th>Season</th>\n",
       "      <th>TimeOfDay</th>\n",
       "      <th>IsWeekend</th>\n",
       "      <th>TemperatureDifference</th>\n",
       "      <th>PressureDifference</th>\n",
       "      <th>DayNightTempDifference</th>\n",
       "      <th>TemperatureLevel</th>\n",
       "      <th>PrecipitationLevel</th>\n",
       "      <th>PressureLevel</th>\n",
       "      <th>HumidityLevel</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:30:00</th>\n",
       "      <td>NSW</td>\n",
       "      <td>6763.57000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1011.1</td>\n",
       "      <td>1006.4</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Night</td>\n",
       "      <td>True</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.26832</td>\n",
       "      <td>Mild</td>\n",
       "      <td>No Precipitation</td>\n",
       "      <td>Normal Pressure</td>\n",
       "      <td>Moderate Moist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:30:00</th>\n",
       "      <td>QLD</td>\n",
       "      <td>3905.56833</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>19.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>1006.2</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Night</td>\n",
       "      <td>True</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.26832</td>\n",
       "      <td>Mild</td>\n",
       "      <td>No Precipitation</td>\n",
       "      <td>Normal Pressure</td>\n",
       "      <td>Moderate Moist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:30:00</th>\n",
       "      <td>SA</td>\n",
       "      <td>1328.68667</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1018.7</td>\n",
       "      <td>1012.6</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Night</td>\n",
       "      <td>True</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.26832</td>\n",
       "      <td>Mild</td>\n",
       "      <td>No Precipitation</td>\n",
       "      <td>Normal Pressure</td>\n",
       "      <td>Moderate Moist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:30:00</th>\n",
       "      <td>VIC</td>\n",
       "      <td>4419.03667</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>10.5</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1013.1</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Night</td>\n",
       "      <td>True</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.26832</td>\n",
       "      <td>Mild</td>\n",
       "      <td>No Precipitation</td>\n",
       "      <td>Normal Pressure</td>\n",
       "      <td>Moderate Moist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 01:00:00</th>\n",
       "      <td>VIC</td>\n",
       "      <td>4312.54000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>63.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>10.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1016.8</td>\n",
       "      <td>1012.9</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Night</td>\n",
       "      <td>True</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.26832</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Light Precipitation</td>\n",
       "      <td>Normal Pressure</td>\n",
       "      <td>Moderate Moist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>TAS</td>\n",
       "      <td>1006.70000</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>1004.6</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Night</td>\n",
       "      <td>False</td>\n",
       "      <td>10.1</td>\n",
       "      <td>10.3</td>\n",
       "      <td>2.26832</td>\n",
       "      <td>Mild</td>\n",
       "      <td>No Precipitation</td>\n",
       "      <td>Normal Pressure</td>\n",
       "      <td>Moderate Moist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>QLD</td>\n",
       "      <td>6218.39000</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>21.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>1013.8</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Night</td>\n",
       "      <td>False</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.26832</td>\n",
       "      <td>Mild</td>\n",
       "      <td>No Precipitation</td>\n",
       "      <td>Normal Pressure</td>\n",
       "      <td>Moderate Moist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>SA</td>\n",
       "      <td>1474.11000</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>12.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Night</td>\n",
       "      <td>False</td>\n",
       "      <td>10.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.26832</td>\n",
       "      <td>Mild</td>\n",
       "      <td>No Precipitation</td>\n",
       "      <td>Normal Pressure</td>\n",
       "      <td>Moderate Moist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>NSW</td>\n",
       "      <td>7318.64000</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>15.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Night</td>\n",
       "      <td>False</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.26832</td>\n",
       "      <td>Mild</td>\n",
       "      <td>No Precipitation</td>\n",
       "      <td>Normal Pressure</td>\n",
       "      <td>Moderate Moist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>VIC</td>\n",
       "      <td>4372.27000</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>12.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Night</td>\n",
       "      <td>False</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.26832</td>\n",
       "      <td>Mild</td>\n",
       "      <td>No Precipitation</td>\n",
       "      <td>Normal Pressure</td>\n",
       "      <td>Moderate Moist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1658965 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Region  TotalDemand  Year  Month  Day  Hour  Minute  \\\n",
       "Date                                                                      \n",
       "2000-01-01 00:30:00    NSW   6763.57000  2000      1    1     0    30.0   \n",
       "2000-01-01 00:30:00    QLD   3905.56833  2000      1    1     0    30.0   \n",
       "2000-01-01 00:30:00     SA   1328.68667  2000      1    1     0    30.0   \n",
       "2000-01-01 00:30:00    VIC   4419.03667  2000      1    1     0    30.0   \n",
       "2000-01-01 01:00:00    VIC   4312.54000  2000      1    1     1     0.0   \n",
       "...                    ...          ...   ...    ...  ...   ...     ...   \n",
       "2020-01-01 00:00:00    TAS   1006.70000  2020      1    1     0     0.0   \n",
       "2020-01-01 00:00:00    QLD   6218.39000  2020      1    1     0     0.0   \n",
       "2020-01-01 00:00:00     SA   1474.11000  2020      1    1     0     0.0   \n",
       "2020-01-01 00:00:00    NSW   7318.64000  2020      1    1     0     0.0   \n",
       "2020-01-01 00:00:00    VIC   4372.27000  2020      1    1     0     0.0   \n",
       "\n",
       "                     Precipitation  RelativeHumidity%  AirTemperature  \\\n",
       "Date                                                                    \n",
       "2000-01-01 00:30:00            0.0               65.0            13.7   \n",
       "2000-01-01 00:30:00            0.0               65.0            13.7   \n",
       "2000-01-01 00:30:00            0.0               65.0            13.2   \n",
       "2000-01-01 00:30:00            0.0               65.0            13.7   \n",
       "2000-01-01 01:00:00            0.8               63.0            13.6   \n",
       "...                            ...                ...             ...   \n",
       "2020-01-01 00:00:00            0.0               61.0            18.8   \n",
       "2020-01-01 00:00:00            0.0               61.0            18.8   \n",
       "2020-01-01 00:00:00            0.0               61.0            18.8   \n",
       "2020-01-01 00:00:00            0.0               61.0            18.8   \n",
       "2020-01-01 00:00:00            0.0               61.0            18.8   \n",
       "\n",
       "                     WetBulbTemperature  DewTemperature  SeaPressure  \\\n",
       "Date                                                                   \n",
       "2000-01-01 00:30:00                14.1             6.8       1011.1   \n",
       "2000-01-01 00:30:00                19.2             6.8       1007.2   \n",
       "2000-01-01 00:30:00                10.1             6.8       1018.7   \n",
       "2000-01-01 00:30:00                10.5             7.2       1017.0   \n",
       "2000-01-01 01:00:00                10.3             6.7       1016.8   \n",
       "...                                 ...             ...          ...   \n",
       "2020-01-01 00:00:00                 9.5             8.7       1014.9   \n",
       "2020-01-01 00:00:00                21.6             8.7       1014.9   \n",
       "2020-01-01 00:00:00                12.3             8.7       1014.9   \n",
       "2020-01-01 00:00:00                15.7             8.7       1014.9   \n",
       "2020-01-01 00:00:00                12.3             8.7       1014.9   \n",
       "\n",
       "                     StationPressure  DayOfWeek  WeekOfMonth  Quarter  \\\n",
       "Date                                                                    \n",
       "2000-01-01 00:30:00           1006.4   Saturday            1        1   \n",
       "2000-01-01 00:30:00           1006.2   Saturday            1        1   \n",
       "2000-01-01 00:30:00           1012.6   Saturday            1        1   \n",
       "2000-01-01 00:30:00           1013.1   Saturday            1        1   \n",
       "2000-01-01 01:00:00           1012.9   Saturday            1        1   \n",
       "...                              ...        ...          ...      ...   \n",
       "2020-01-01 00:00:00           1004.6  Wednesday            1        1   \n",
       "2020-01-01 00:00:00           1013.8  Wednesday            1        1   \n",
       "2020-01-01 00:00:00           1010.6  Wednesday            1        1   \n",
       "2020-01-01 00:00:00           1008.8  Wednesday            1        1   \n",
       "2020-01-01 00:00:00           1014.0  Wednesday            1        1   \n",
       "\n",
       "                     DayOfYear  Season TimeOfDay  IsWeekend  \\\n",
       "Date                                                          \n",
       "2000-01-01 00:30:00          1  Summer     Night       True   \n",
       "2000-01-01 00:30:00          1  Summer     Night       True   \n",
       "2000-01-01 00:30:00          1  Summer     Night       True   \n",
       "2000-01-01 00:30:00          1  Summer     Night       True   \n",
       "2000-01-01 01:00:00          1  Summer     Night       True   \n",
       "...                        ...     ...       ...        ...   \n",
       "2020-01-01 00:00:00          1  Summer     Night      False   \n",
       "2020-01-01 00:00:00          1  Summer     Night      False   \n",
       "2020-01-01 00:00:00          1  Summer     Night      False   \n",
       "2020-01-01 00:00:00          1  Summer     Night      False   \n",
       "2020-01-01 00:00:00          1  Summer     Night      False   \n",
       "\n",
       "                     TemperatureDifference  PressureDifference  \\\n",
       "Date                                                             \n",
       "2000-01-01 00:30:00                    6.9                 4.7   \n",
       "2000-01-01 00:30:00                    6.9                 1.0   \n",
       "2000-01-01 00:30:00                    6.4                 6.1   \n",
       "2000-01-01 00:30:00                    6.5                 3.9   \n",
       "2000-01-01 01:00:00                    6.9                 3.9   \n",
       "...                                    ...                 ...   \n",
       "2020-01-01 00:00:00                   10.1                10.3   \n",
       "2020-01-01 00:00:00                   10.1                 1.1   \n",
       "2020-01-01 00:00:00                   10.1                 4.3   \n",
       "2020-01-01 00:00:00                   10.1                 6.1   \n",
       "2020-01-01 00:00:00                   10.1                 0.9   \n",
       "\n",
       "                     DayNightTempDifference TemperatureLevel  \\\n",
       "Date                                                           \n",
       "2000-01-01 00:30:00                 2.26832             Mild   \n",
       "2000-01-01 00:30:00                 2.26832             Mild   \n",
       "2000-01-01 00:30:00                 2.26832             Mild   \n",
       "2000-01-01 00:30:00                 2.26832             Mild   \n",
       "2000-01-01 01:00:00                 2.26832             Mild   \n",
       "...                                     ...              ...   \n",
       "2020-01-01 00:00:00                 2.26832             Mild   \n",
       "2020-01-01 00:00:00                 2.26832             Mild   \n",
       "2020-01-01 00:00:00                 2.26832             Mild   \n",
       "2020-01-01 00:00:00                 2.26832             Mild   \n",
       "2020-01-01 00:00:00                 2.26832             Mild   \n",
       "\n",
       "                      PrecipitationLevel    PressureLevel   HumidityLevel  \n",
       "Date                                                                       \n",
       "2000-01-01 00:30:00     No Precipitation  Normal Pressure  Moderate Moist  \n",
       "2000-01-01 00:30:00     No Precipitation  Normal Pressure  Moderate Moist  \n",
       "2000-01-01 00:30:00     No Precipitation  Normal Pressure  Moderate Moist  \n",
       "2000-01-01 00:30:00     No Precipitation  Normal Pressure  Moderate Moist  \n",
       "2000-01-01 01:00:00  Light Precipitation  Normal Pressure  Moderate Moist  \n",
       "...                                  ...              ...             ...  \n",
       "2020-01-01 00:00:00     No Precipitation  Normal Pressure  Moderate Moist  \n",
       "2020-01-01 00:00:00     No Precipitation  Normal Pressure  Moderate Moist  \n",
       "2020-01-01 00:00:00     No Precipitation  Normal Pressure  Moderate Moist  \n",
       "2020-01-01 00:00:00     No Precipitation  Normal Pressure  Moderate Moist  \n",
       "2020-01-01 00:00:00     No Precipitation  Normal Pressure  Moderate Moist  \n",
       "\n",
       "[1658965 rows x 28 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_table=create_master_table(energy_data, temperature_data)\n",
    "master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3410d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save master_table to a pickle file\n",
    "master_table.to_pickle('master_table.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05a6b1",
   "metadata": {},
   "source": [
    "# 09- Encoding categorical variables\n",
    "\n",
    "The foloowing function one_hot_encode_columns takes a DataFrame master_table as input and performs one-hot encoding on specified categorical columns: 'DayOfWeek', 'Season', 'TimeOfDay', 'IsWeekend', 'IsSummer', 'IsWinter', 'IsDaytime', 'IsNighttime', 'IsHoliday', 'TemperatureLevel', 'PrecipitationLevel', 'PressureLevel', and 'HumidityLevel'. It begins by creating a copy of the original DataFrame to preserve the original data. Then, it initializes a OneHotEncoder object from scikit-learn. The fit_transform method of the OneHotEncoder is applied to the specified categorical columns to generate the encoded columns. The encoded column names are retrieved using the get_feature_names_out method. A new DataFrame, encoded_df, is created using the encoded columns and their names. Next, the original categorical columns are dropped from the data_encoded DataFrame. The index of both dataframes is reset, and then they are concatenated along the columns axis. Finally, a new 'Date' column is created by combining the 'Year', 'Month', 'Day', and 'Hour' columns and set as the index of the resulting DataFrame before returning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "075b1650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Region', 'TotalDemand', 'Year', 'Month', 'Day', 'Hour', 'Minute',\n",
       "       'Precipitation', 'RelativeHumidity%', 'AirTemperature',\n",
       "       'WetBulbTemperature', 'DewTemperature', 'SeaPressure',\n",
       "       'StationPressure', 'DayOfWeek', 'WeekOfMonth', 'Quarter', 'DayOfYear',\n",
       "       'Season', 'TimeOfDay', 'IsWeekend', 'TemperatureDifference',\n",
       "       'PressureDifference', 'DayNightTempDifference', 'TemperatureLevel',\n",
       "       'PrecipitationLevel', 'PressureLevel', 'HumidityLevel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff81b592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region                    category\n",
       "TotalDemand                float64\n",
       "Year                         int16\n",
       "Month                        uint8\n",
       "Day                          uint8\n",
       "Hour                         uint8\n",
       "Minute                     float64\n",
       "Precipitation              float64\n",
       "RelativeHumidity%          float64\n",
       "AirTemperature             float64\n",
       "WetBulbTemperature         float64\n",
       "DewTemperature             float64\n",
       "SeaPressure                float64\n",
       "StationPressure            float64\n",
       "DayOfWeek                   object\n",
       "WeekOfMonth                  uint8\n",
       "Quarter                      uint8\n",
       "DayOfYear                   uint16\n",
       "Season                      object\n",
       "TimeOfDay                   object\n",
       "IsWeekend                     bool\n",
       "TemperatureDifference      float32\n",
       "PressureDifference         float32\n",
       "DayNightTempDifference     float32\n",
       "TemperatureLevel          category\n",
       "PrecipitationLevel        category\n",
       "PressureLevel             category\n",
       "HumidityLevel             category\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_table.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1aec9891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_columns(master_table):\n",
    "     \n",
    "    # Copying the DataFrame\n",
    "    data_encoded = master_table.copy()\n",
    "    \n",
    "    # Initializing OneHotEncoder\n",
    "    onehot_encoder = OneHotEncoder()\n",
    "    \n",
    "    # The fit_transform method of the OneHotEncoder object is appling to the specified categorical columns\n",
    "    encoded_cols = onehot_encoder.fit_transform(master_table[['DayOfWeek', 'Season','TimeOfDay', 'IsWeekend','TemperatureLevel','PrecipitationLevel', 'PressureLevel',\n",
    "                                                              'HumidityLevel']])\n",
    "    \n",
    "    # Retrieving Encoded Column Names\n",
    "    encoded_column_names = onehot_encoder.get_feature_names_out(['DayOfWeek', 'Season','TimeOfDay', 'IsWeekend','TemperatureLevel','PrecipitationLevel', \n",
    "                                                                 'PressureLevel','HumidityLevel'])\n",
    "    # Creating Encoded DataFrame\n",
    "    encoded_df = pd.DataFrame(encoded_cols.toarray(), columns=encoded_column_names)\n",
    "    \n",
    "    # Dropping Original Categorical Columns\n",
    "    data_encoded = data_encoded.drop(['DayOfWeek', 'Season','TimeOfDay', 'IsWeekend', 'TemperatureLevel','PrecipitationLevel', 'PressureLevel',\n",
    "                                      'HumidityLevel'], axis=1)\n",
    "    \n",
    "    # Resetting Index\n",
    "    encoded_df.reset_index(drop=True, inplace=True)\n",
    "    data_encoded.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Concatenating DataFrames\n",
    "    data_encoded = pd.concat([data_encoded, encoded_df], axis=1)\n",
    "\n",
    "    # Create the \"Date\" column from \"Year\", \"Month\", \"Day\", \"Hour\", and \"Minute\" columns and set as the index\n",
    "    data_encoded[\"Date\"] = pd.to_datetime(data_encoded[[\"Year\", \"Month\", \"Day\", \"Hour\"]])\n",
    "    data_encoded.set_index(\"Date\", inplace=True)\n",
    "    \n",
    "    return data_encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15ff33df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded= one_hot_encode_columns(master_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "932b9047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Region', 'TotalDemand', 'Year', 'Month', 'Day', 'Hour', 'Minute',\n",
       "       'Precipitation', 'RelativeHumidity%', 'AirTemperature',\n",
       "       'WetBulbTemperature', 'DewTemperature', 'SeaPressure',\n",
       "       'StationPressure', 'WeekOfMonth', 'Quarter', 'DayOfYear',\n",
       "       'TemperatureDifference', 'PressureDifference', 'DayNightTempDifference',\n",
       "       'DayOfWeek_Friday', 'DayOfWeek_Monday', 'DayOfWeek_Saturday',\n",
       "       'DayOfWeek_Sunday', 'DayOfWeek_Thursday', 'DayOfWeek_Tuesday',\n",
       "       'DayOfWeek_Wednesday', 'Season_Autumn', 'Season_Spring',\n",
       "       'Season_Summer', 'Season_Winter', 'TimeOfDay_Afternoon',\n",
       "       'TimeOfDay_Evening', 'TimeOfDay_Morning', 'TimeOfDay_Night',\n",
       "       'IsWeekend_False', 'IsWeekend_True', 'TemperatureLevel_Cold',\n",
       "       'TemperatureLevel_Hot', 'TemperatureLevel_Mild',\n",
       "       'TemperatureLevel_Very Cold', 'TemperatureLevel_Warm',\n",
       "       'PrecipitationLevel_Heavy Precipitation',\n",
       "       'PrecipitationLevel_Light Precipitation',\n",
       "       'PrecipitationLevel_Moderate Precipitation',\n",
       "       'PrecipitationLevel_No Precipitation', 'PressureLevel_High Pressure',\n",
       "       'PressureLevel_Low Pressure', 'PressureLevel_Normal Pressure',\n",
       "       'HumidityLevel_High Moist', 'HumidityLevel_Low Moist',\n",
       "       'HumidityLevel_Moderate Moist'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec1268f",
   "metadata": {},
   "source": [
    "# 10- Resampling each group to an hourly frequency\n",
    "\n",
    "The following function groups the data by the specified region column and resamples it to hourly intervals, calculating the mean value for each interval. This resampling process effectively aggregates the data to hourly resolution, which can be beneficial for various analyses, especially when aligning energy consumption and temperature data for further analysis or modeling. Furthermore, it effectively reduced the potential risk of overfitting caused by including excessively detailed temporal information, and it can help reduce the impact of anomalies or outliers present in the original data. After resampling, the function resets the index to include the region column and sorts the data by index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd461c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data_to_hourly(data_encoded):\n",
    "    \n",
    "    # Group by region and resample to hourly intervals, calculating mean\n",
    "    resampled_data = data_encoded.groupby(\"Region\").resample(\"H\").mean().reset_index(\"Region\").sort_index()\n",
    "    \n",
    "     # Drop unnecessary columns\n",
    "    resampled_data.drop([\"Minute\"], axis=1, inplace=True)\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    resampled_data.dropna(inplace=True)\n",
    "    \n",
    "    # Convert to appropriate integer data types\n",
    "    resampled_data['Year'] = resampled_data['Year'].astype(np.int16)\n",
    "    resampled_data['Month'] = resampled_data['Month'].astype(np.uint8)\n",
    "    resampled_data['Day'] = resampled_data['Day'].astype(np.uint8)\n",
    "    resampled_data['Hour'] = resampled_data['Hour'].astype(np.uint8)\n",
    "    resampled_data['WeekOfMonth'] = resampled_data['WeekOfMonth'].astype(np.uint8)\n",
    "    resampled_data['Quarter'] = resampled_data['Quarter'].astype(np.uint8)\n",
    "    resampled_data['DayOfYear'] = resampled_data['DayOfYear'].astype(np.uint16)\n",
    "    \n",
    "    # List of columns to convert to integer\n",
    "    binary_columns = ['DayOfWeek_Friday', 'DayOfWeek_Monday', 'DayOfWeek_Saturday', 'DayOfWeek_Sunday','DayOfWeek_Thursday', \n",
    "                      'DayOfWeek_Tuesday', 'DayOfWeek_Wednesday', 'Season_Autumn','Season_Spring', 'Season_Summer', \n",
    "                      'Season_Winter', 'TimeOfDay_Afternoon', 'TimeOfDay_Evening','TimeOfDay_Morning', 'TimeOfDay_Night',\n",
    "                      'IsWeekend_False', 'IsWeekend_True', 'TemperatureLevel_Cold', 'TemperatureLevel_Hot', 'TemperatureLevel_Mild',\n",
    "                      'TemperatureLevel_Very Cold', 'TemperatureLevel_Warm','PrecipitationLevel_Heavy Precipitation', 'PrecipitationLevel_Light Precipitation',\n",
    "                      'PrecipitationLevel_Moderate Precipitation', 'PrecipitationLevel_No Precipitation','PressureLevel_High Pressure', \n",
    "                      'PressureLevel_Low Pressure', 'PressureLevel_Normal Pressure','HumidityLevel_High Moist', 'HumidityLevel_Low Moist', \n",
    "                      'HumidityLevel_Moderate Moist']\n",
    "\n",
    "    # Convert the binary columns to integer type\n",
    "    resampled_data[binary_columns] = resampled_data[binary_columns].astype('int16')\n",
    "    \n",
    "    # Filter the data from 2010 onwards\n",
    "    resampled_data = resampled_data.loc['2010':]\n",
    "\n",
    "    return resampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2a96384",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_data = resample_data_to_hourly(data_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74d7e1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to a pickle file\n",
    "resampled_data.to_pickle('resampled_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3802c3c-2cc7-418a-a733-6942ba181310",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
