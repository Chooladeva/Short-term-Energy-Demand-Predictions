{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e40275d6",
   "metadata": {},
   "source": [
    "### Importing required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbf7d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08107e1c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaab0d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Preprocessed resampled_data from the pickle file\n",
    "def load_from_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "resampled_data = load_from_pickle('resampled_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9affc7d6",
   "metadata": {},
   "source": [
    "### Deriving the best hyperparameters for the most influential features selected among regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "238179ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RandomState instance with a specific seed\n",
    "random_state = np.random.RandomState(seed=42)\n",
    "    \n",
    "# Train-test split without shuffling\n",
    "train_data, test_data = train_test_split(resampled_data, shuffle=False, random_state=random_state)\n",
    "    \n",
    " # Define input and output columns\n",
    "input_columns = ['Precipitation', 'RelativeHumidity%', 'AirTemperature','WetBulbTemperature', 'DewTemperature', 'SeaPressure', \n",
    "                 'StationPressure', 'Month', 'Day', 'Hour', 'DayOfYear', 'Season_Autumn', 'Season_Spring', 'Season_Summer', \n",
    "                 'Season_Winter', 'TimeOfDay_Afternoon', 'TimeOfDay_Evening','TimeOfDay_Morning', 'TimeOfDay_Night', \n",
    "                 'IsWeekend_False', 'IsWeekend_True'\n",
    "                ]\n",
    "output_columns = [\"TotalDemand\"]\n",
    "\n",
    "# Select input and output data with \"Region\" for training data\n",
    "train_input_data = train_data[input_columns + [\"Region\"]]\n",
    "train_output_data = train_data[output_columns + [\"Region\"]]\n",
    "\n",
    "# Select input and output data with \"Region\" for testing data\n",
    "test_input_data = test_data[input_columns + [\"Region\"]]\n",
    "test_output_data = test_data[output_columns + [\"Region\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "314017a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(test_input: pd.DataFrame, test_output: pd.DataFrame):\n",
    "    \n",
    "    # Define the parameter grid for random search\n",
    "    random_param_grid = {\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "        'max_depth': [5, 6, 7, 8],\n",
    "        'n_estimators': [200, 300, 400, 500],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "        'bagging_fraction': [0.7, 0.8, 0.9, 1.0],\n",
    "        'min_child_samples': [5, 10, 20, 50, 100],\n",
    "        'boosting_type': ['gbdt', 'dart', 'goss']\n",
    "    }\n",
    "    \n",
    "    # Initialize the LightGBM Regressor model\n",
    "    regressor = LGBMRegressor(random_state=42, verbose=-1, n_jobs=-1)\n",
    "        \n",
    "    # Perform random search\n",
    "    random_search = RandomizedSearchCV(regressor, param_distributions=random_param_grid, n_iter=10, cv=3, random_state=42, n_jobs=-1)\n",
    "    random_search.fit(test_input, test_output.values.ravel())\n",
    "        \n",
    "    # Get the best hyperparameters and the best model from random search\n",
    "    best_params_ran = random_search.best_params_\n",
    "    best_model = random_search.best_estimator_\n",
    "        \n",
    "    # Define the parameter grid for grid search using the best params from random search\n",
    "    grid_param_grid = {\n",
    "        'learning_rate': [best_params_ran['learning_rate']],\n",
    "        'max_depth': [best_params_ran['max_depth'] - 1, best_params_ran['max_depth'], best_params_ran['max_depth'] + 1],\n",
    "        'n_estimators': [best_params_ran['n_estimators'] - 50, best_params_ran['n_estimators'], best_params_ran['n_estimators'] + 50],\n",
    "        'subsample': [best_params_ran['subsample']],\n",
    "        'colsample_bytree': [best_params_ran['colsample_bytree']],\n",
    "        'bagging_fraction': [best_params_ran['bagging_fraction']],\n",
    "        'min_child_samples': [best_params_ran['min_child_samples']],\n",
    "        'boosting_type': [best_params_ran['boosting_type']]\n",
    "    }\n",
    "    \n",
    "    # Perform grid search\n",
    "    grid = GridSearchCV(regressor, param_grid=grid_param_grid, n_jobs=-1)\n",
    "    grid.fit(test_input, test_output.values.ravel())\n",
    "\n",
    "    best_score = grid.best_score_\n",
    "    best_params = grid.best_params_\n",
    "    \n",
    "    return grid, best_score, best_params      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a08fc175",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_predictions(regressor, test_input, test_output, train_input=None, train_output=None):\n",
    "    \n",
    "    test_predictions = regressor.predict(test_input)\n",
    "    test_results = pd.DataFrame(test_predictions, columns=output_columns, index=test_input.index)\n",
    "    test_results = test_input.join(test_results)\n",
    "    \n",
    "    if train_input is not None and train_output is not None: \n",
    "        train_predictions = regressor.predict(train_input)\n",
    "        train_results = pd.DataFrame(train_predictions, columns=output_columns, index=train_input.index)\n",
    "        train_results = train_input.join(train_results)\n",
    "        \n",
    "        return test_results, train_results\n",
    "    \n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fdb4e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best NSW model has a score of 0.8142628048304628 and best params {'bagging_fraction': 0.7, 'boosting_type': 'goss', 'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 7, 'min_child_samples': 20, 'n_estimators': 250, 'subsample': 1.0}\n",
      "Best QLD model has a score of 0.8337583180520138 and best params {'bagging_fraction': 0.7, 'boosting_type': 'goss', 'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_samples': 20, 'n_estimators': 250, 'subsample': 1.0}\n",
      "Best SA model has a score of 0.6620201561704514 and best params {'bagging_fraction': 0.7, 'boosting_type': 'goss', 'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 7, 'min_child_samples': 20, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Best TAS model has a score of 0.7728150057772355 and best params {'bagging_fraction': 0.7, 'boosting_type': 'goss', 'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 7, 'min_child_samples': 20, 'n_estimators': 250, 'subsample': 1.0}\n",
      "Best VIC model has a score of 0.804533125065072 and best params {'bagging_fraction': 0.7, 'boosting_type': 'gbdt', 'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_samples': 50, 'n_estimators': 450, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models, regressors = [], []\n",
    "\n",
    "test_predictions, train_predictions = [], []\n",
    "\n",
    "for region, dataframe in train_data.groupby(\"Region\"):\n",
    "    \n",
    "    # Cross validate to find the best model\n",
    "    model_input, model_output = dataframe.dropna()[input_columns], dataframe.dropna()[output_columns]\n",
    "    grid, score, params = get_best_model(model_input, model_output)\n",
    "    regressors.append(grid)\n",
    "    models.append(regressors[-1].fit(model_input, model_output.values.ravel()))\n",
    "    \n",
    "    print(f\"Best {region} model has a score of {score} and best params {params}\")\n",
    "    \n",
    "    # Get the test data for this specific region\n",
    "    test_input = test_data.groupby(\"Region\").get_group(region)[input_columns].dropna()\n",
    "    test_output = test_data.groupby(\"Region\").get_group(region)[output_columns].dropna()\n",
    "    \n",
    "    # Generate predictions, obtain and log the final formatted data\n",
    "    test_results, train_results = get_predictions(regressors[-1], test_input, test_output, model_input, model_output)\n",
    "    test_predictions.append(test_results)\n",
    "    train_predictions.append(train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9f6929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models and their parameters to a pickle file\n",
    "with open(\"trained_models.pickle\", \"wb\") as f:\n",
    "    pickle.dump((models, [regressor.best_params_ for regressor in regressors]), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489d2e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained models and their best parameters from the pickle file\n",
    "with open('trained_models.pickle', 'rb') as f:\n",
    "    models, best_params = pickle.load(f)\n",
    "\n",
    "# Create a dictionary to map regions to their corresponding models\n",
    "regions = ['NSW', 'QLD', 'SA', 'TAS', 'VIC']\n",
    "trained_models_dict = dict(zip(regions, models))\n",
    "\n",
    "nsw_model = trained_models_dict['NSW']\n",
    "nsw_best_params = best_params[regions.index('NSW')]\n",
    "\n",
    "qld_model = trained_models_dict['QLD']\n",
    "qld_best_params = best_params[regions.index('QLD')]\n",
    "\n",
    "sa_model = trained_models_dict['SA']\n",
    "sa_best_params = best_params[regions.index('SA')]\n",
    "\n",
    "tas_model = trained_models_dict['TAS']\n",
    "tas_best_params = best_params[regions.index('TAS')]\n",
    "\n",
    "vic_model = trained_models_dict['VIC']\n",
    "vic_best_params = best_params[regions.index('VIC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a69229e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.7,\n",
       " 'boosting_type': 'goss',\n",
       " 'colsample_bytree': 0.7,\n",
       " 'learning_rate': 0.05,\n",
       " 'max_depth': 7,\n",
       " 'min_child_samples': 20,\n",
       " 'n_estimators': 250,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.7,\n",
       " 'boosting_type': 'goss',\n",
       " 'colsample_bytree': 0.7,\n",
       " 'learning_rate': 0.05,\n",
       " 'max_depth': 6,\n",
       " 'min_child_samples': 20,\n",
       " 'n_estimators': 250,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.7,\n",
       " 'boosting_type': 'goss',\n",
       " 'colsample_bytree': 0.7,\n",
       " 'learning_rate': 0.05,\n",
       " 'max_depth': 7,\n",
       " 'min_child_samples': 20,\n",
       " 'n_estimators': 200,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.7,\n",
       " 'boosting_type': 'goss',\n",
       " 'colsample_bytree': 0.7,\n",
       " 'learning_rate': 0.05,\n",
       " 'max_depth': 7,\n",
       " 'min_child_samples': 20,\n",
       " 'n_estimators': 250,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.7,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'colsample_bytree': 0.7,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 8,\n",
       " 'min_child_samples': 50,\n",
       " 'n_estimators': 450,\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve best parameters for each region\n",
    "nsw_best_params\n",
    "qld_best_params\n",
    "sa_best_params\n",
    "tas_best_params\n",
    "vic_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bcdf1d",
   "metadata": {},
   "source": [
    "### Training the model for each region with best parameters derived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "723e968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = resampled_data[['Region','Precipitation', 'RelativeHumidity%', 'AirTemperature', 'WetBulbTemperature', \n",
    "                                'DewTemperature', 'SeaPressure', 'StationPressure', 'Month', 'Day', 'Hour', \n",
    "                                'DayOfYear', 'Season_Autumn', 'Season_Spring', 'Season_Summer', 'Season_Winter', \n",
    "                                'TimeOfDay_Afternoon', 'TimeOfDay_Evening', 'TimeOfDay_Morning', 'TimeOfDay_Night', \n",
    "                                'IsWeekend_False', 'IsWeekend_True', 'TotalDemand']]\n",
    "\n",
    "# Save data to a pickle file\n",
    "data.to_pickle('data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cac512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a LightGBM model with best parameters\n",
    "def create_lgb_model(best_params):\n",
    "    model = LGBMRegressor(**best_params, n_jobs=-1, random_state=42, verbose=-1)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Function to train LightGBM model for a specific region\n",
    "def train_lgb_model(data, region, input_columns, output_columns, best_params):\n",
    "    \n",
    "    # Filter data for the specified region\n",
    "    region_data = data[data['Region'] == region]\n",
    "    \n",
    "    # Prepare the input features and target variable\n",
    "    data_X = region_data[input_columns]\n",
    "    data_y = region_data[output_columns]\n",
    "    \n",
    "    # Train-test split without shuffling\n",
    "    random_state = np.random.RandomState(seed=42)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, shuffle=False, random_state=random_state)\n",
    "    \n",
    "    # Create and fit the LightGBM model with best parameters\n",
    "    model = create_lgb_model(best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eb8009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for Region NSW\n",
    "nsw_model, nsw_X_test, nsw_y_test = train_lgb_model(data, 'NSW', input_columns, output_columns, nsw_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80af4e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for Region SA\n",
    "sa_model, sa_X_test, sa_y_test = train_lgb_model(data, 'SA', input_columns, output_columns, sa_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d997a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for Region QLD\n",
    "qld_model, qld_X_test, qld_y_test = train_lgb_model(data, 'QLD', input_columns, output_columns, qld_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b42e3efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for Region QLD\n",
    "vic_model, vic_X_test, vic_y_test = train_lgb_model(data, 'VIC', input_columns, output_columns, vic_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7ac353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for Region TAS\n",
    "tas_model, tas_X_test, tas_y_test = train_lgb_model(data, 'TAS', input_columns, output_columns, tas_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbcbf25",
   "metadata": {},
   "source": [
    "### Saving the individual regional models in pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d430ee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for NSW region to a pickle file\n",
    "with open('nsw_model.pickle', 'wb') as f:\n",
    "    pickle.dump(nsw_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd208c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for SA region to a pickle file\n",
    "with open('sa_model.pickle', 'wb') as f:\n",
    "    pickle.dump(sa_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b37a294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for QLD region to a pickle file\n",
    "with open('qld_model.pickle', 'wb') as f:\n",
    "    pickle.dump(qld_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "868e5d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for VIC region to a pickle file\n",
    "with open('vic_model.pickle', 'wb') as f:\n",
    "    pickle.dump(vic_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "310c035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for TAS region to a pickle file\n",
    "with open('tas_model.pickle', 'wb') as f:\n",
    "    pickle.dump(tas_model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
