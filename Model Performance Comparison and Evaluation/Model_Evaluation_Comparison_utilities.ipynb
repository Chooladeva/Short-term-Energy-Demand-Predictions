{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c05dd1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries \n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.set(style='ticks')\n",
    "sns.set_style('white')\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Load resampled_data from the pickle file\n",
    "def load_from_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "def create_train_test_split(resampled_data):\n",
    "    \n",
    "     # Create a RandomState instance with a specific seed\n",
    "    random_state = np.random.RandomState(seed=42)\n",
    "    \n",
    "    # Train-test split without shuffling\n",
    "    train_data, test_data = train_test_split(resampled_data, shuffle=False, random_state=random_state)\n",
    "    \n",
    "    # Define input and output columns\n",
    "    input_columns = ['Month', 'Day', 'Hour','Precipitation', 'AirTemperature', 'WetBulbTemperature','DewTemperature','RelativeHumidity%','SeaPressure',\n",
    "                     'StationPressure','WeekOfMonth', 'Quarter', 'DayOfYear', 'TemperatureDifference','PressureDifference','DayNightTempDifference',\n",
    "                     'DayOfWeek_Friday', 'DayOfWeek_Monday', 'DayOfWeek_Saturday','DayOfWeek_Sunday', 'DayOfWeek_Thursday', 'DayOfWeek_Tuesday',\n",
    "                     'DayOfWeek_Wednesday', 'Season_Autumn', 'Season_Spring','Season_Summer', 'Season_Winter','TimeOfDay_Afternoon','TimeOfDay_Evening',\n",
    "                     'TimeOfDay_Morning', 'TimeOfDay_Night', 'IsWeekend_False', 'IsWeekend_True', 'TemperatureLevel_Cold', 'TemperatureLevel_Hot',\n",
    "                     'TemperatureLevel_Mild', 'TemperatureLevel_Very Cold','TemperatureLevel_Warm', 'PrecipitationLevel_Heavy Precipitation',\n",
    "                     'PrecipitationLevel_Light Precipitation','PrecipitationLevel_Moderate Precipitation','PrecipitationLevel_No Precipitation',\n",
    "                     'PressureLevel_High Pressure','PressureLevel_Low Pressure','PressureLevel_Normal Pressure','HumidityLevel_High Moist',\n",
    "                     'HumidityLevel_Low Moist','HumidityLevel_Moderate Moist']\n",
    "    output_columns = [\"TotalDemand\"]\n",
    "\n",
    "    # Select input and output data with \"Region\" for training data\n",
    "    train_input_data = train_data[input_columns + [\"Region\"]]\n",
    "    train_output_data = train_data[output_columns + [\"Region\"]]\n",
    "\n",
    "    # Select input and output data with \"Region\" for testing data\n",
    "    test_input_data = test_data[input_columns + [\"Region\"]]\n",
    "    test_output_data = test_data[output_columns + [\"Region\"]]\n",
    "    \n",
    "    return train_input_data, train_output_data, test_input_data, test_output_data\n",
    "\n",
    "\n",
    "def ExtraTrees(train_input_data, train_output_data):\n",
    "    \n",
    "    ET_trained = {}  # Dictionary to store trained models for each region\n",
    "    \n",
    "    # Iterate over each region in the training data\n",
    "    for region, dataframe in train_input_data.groupby(\"Region\"):\n",
    "        \n",
    "        # Select the data for the current region\n",
    "        region_train_input = dataframe.drop(columns=[\"Region\"])\n",
    "        region_train_output = train_output_data[train_output_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        \n",
    "        # Initialize and train the ExtraTreesRegressor model\n",
    "        regressor = ExtraTreesRegressor(random_state=42, n_jobs=-1)\n",
    "        regressor.fit(region_train_input, region_train_output.values.flatten())\n",
    "        \n",
    "        # Store the trained model in the dictionary\n",
    "        ET_trained[region] = regressor\n",
    "    \n",
    "    return ET_trained\n",
    "\n",
    "def get_predictions(trained_models_et, test_input_data, test_output_data, train_input_data=None):\n",
    "    \n",
    "    test_predictions_ET = {}  # Dictionary to store test predictions for each region\n",
    "    train_predictions_ET = {}  # Dictionary to store train predictions for each region\n",
    "    \n",
    "    # Iterate over each region\n",
    "    for region, model in trained_models_et.items():\n",
    "        \n",
    "        # Retrieve the test input and output data for the current region\n",
    "        region_test_input = test_input_data[test_input_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        region_test_output = test_output_data[test_output_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        \n",
    "        # Generate predictions on test data\n",
    "        test_pred = model.predict(region_test_input)\n",
    "        test_predictions_ET[region] = test_pred\n",
    "        \n",
    "        if train_input_data is not None:\n",
    "            \n",
    "            # If train data is provided, generate predictions on train data as well\n",
    "            region_train_input = train_input_data[train_input_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "            train_pred = model.predict(region_train_input)\n",
    "            train_predictions_ET[region] = train_pred\n",
    "    \n",
    "    return test_predictions_ET, train_predictions_ET\n",
    "\n",
    "def evaluate_model(test_output_data, test_predictions_ET, train_output_data, train_predictions_ET):\n",
    "    \n",
    "    # Initialize dictionaries to store evaluation metrics for test and train data\n",
    "    evaluation_metrics_test_ET = {}\n",
    "    evaluation_metrics_train_ET = {}\n",
    "\n",
    "    # Calculate evaluation metrics for test data\n",
    "    for region in test_output_data[\"Region\"].unique():\n",
    "        actual_test = test_output_data[test_output_data[\"Region\"] == region][\"TotalDemand\"].values\n",
    "        predicted_test = test_predictions_ET[region]\n",
    "        if len(actual_test) == len(predicted_test):  # Ensure the same number of samples\n",
    "            mse_test = mean_squared_error(actual_test, predicted_test)\n",
    "            rmse_test = np.sqrt(mse_test)\n",
    "            mae_test = mean_absolute_error(actual_test, predicted_test)\n",
    "            r2_test = r2_score(actual_test, predicted_test)\n",
    "            n = len(actual_test)\n",
    "            # Number of predictors used in the model (excluding the intercept)\n",
    "            p_test = test_output_data.shape[1] - 1  # Subtract 1 for the intercept\n",
    "            adjusted_r2_test = 1 - (1 - r2_test) * (n - 1) / (n - p_test - 1)\n",
    "            evaluation_metrics_test_ET[region] = {\"MSE\": mse_test, \"RMSE\": rmse_test, \"MAE\": mae_test, \"R-squared\": r2_test, \"Adjusted R-squared\": adjusted_r2_test}\n",
    "\n",
    "    # Calculate evaluation metrics for train data\n",
    "    for region in train_output_data[\"Region\"].unique():\n",
    "        actual_train = train_output_data[train_output_data[\"Region\"] == region][\"TotalDemand\"].values\n",
    "        predicted_train = train_predictions_ET[region]\n",
    "        if len(actual_train) == len(predicted_train):  # Ensure the same number of samples\n",
    "            mse_train = mean_squared_error(actual_train, predicted_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            mae_train = mean_absolute_error(actual_train, predicted_train)\n",
    "            r2_train = r2_score(actual_train, predicted_train)\n",
    "            n = len(actual_train)\n",
    "            # Number of predictors used in the model (excluding the intercept)\n",
    "            p_train = train_output_data.shape[1] - 1  # Subtract 1 for the intercept\n",
    "            adjusted_r2_train = 1 - (1 - r2_train) * (n - 1) / (n - p_train - 1)\n",
    "            evaluation_metrics_train_ET[region] = {\"MSE\": mse_train, \"RMSE\": rmse_train, \"MAE\": mae_train, \"R-squared\": r2_train, \"Adjusted R-squared\": adjusted_r2_train}\n",
    "\n",
    "    return evaluation_metrics_test_ET, evaluation_metrics_train_ET\n",
    "\n",
    "def GradientBoosting(train_input_data, train_output_data):\n",
    "    \n",
    "    GBR_trained = {}  # Dictionary to store trained models for each region\n",
    "    \n",
    "    # Iterate over each region in the training data\n",
    "    for region, dataframe in train_input_data.groupby(\"Region\"):\n",
    "        \n",
    "        # Select the data for the current region\n",
    "        region_train_input = dataframe.drop(columns=[\"Region\"])\n",
    "        region_train_output = train_output_data[train_output_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        \n",
    "        # Initialize and train the GradientBoostingRegressor model\n",
    "        regressor = GradientBoostingRegressor(random_state=42)\n",
    "        regressor.fit(region_train_input, region_train_output.values.flatten())\n",
    "        \n",
    "        # Store the trained model in the dictionary\n",
    "        GBR_trained[region] = regressor\n",
    "    \n",
    "    return GBR_trained\n",
    "\n",
    "def get_predictions(trained_models_gbr, test_input_data, test_output_data, train_input_data=None):\n",
    "    \n",
    "    test_predictions_GBR = {}  # Dictionary to store test predictions for each region\n",
    "    train_predictions_GBR = {}  # Dictionary to store train predictions for each region\n",
    "    \n",
    "    # Iterate over each region\n",
    "    for region, model in trained_models_gbr.items():\n",
    "        \n",
    "        # Retrieve the test input and output data for the current region\n",
    "        region_test_input = test_input_data[test_input_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        region_test_output = test_output_data[test_output_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        \n",
    "        # Generate predictions on test data\n",
    "        test_pred = model.predict(region_test_input)\n",
    "        test_predictions_GBR[region] = test_pred\n",
    "        \n",
    "        if train_input_data is not None:\n",
    "            \n",
    "            # If train data is provided, generate predictions on train data as well\n",
    "            region_train_input = train_input_data[train_input_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "            train_pred = model.predict(region_train_input)\n",
    "            train_predictions_GBR[region] = train_pred\n",
    "    \n",
    "    return test_predictions_GBR, train_predictions_GBR\n",
    "\n",
    "def evaluate_model(test_output_data, test_predictions_GBR, train_output_data, train_predictions_GBR):\n",
    "    \n",
    "    # Initialize dictionaries to store evaluation metrics for test and train data\n",
    "    evaluation_metrics_test_GBR = {}\n",
    "    evaluation_metrics_train_GBR = {}\n",
    "\n",
    "    # Calculate evaluation metrics for test data\n",
    "    for region in test_output_data[\"Region\"].unique():\n",
    "        actual_test = test_output_data[test_output_data[\"Region\"] == region][\"TotalDemand\"].values\n",
    "        predicted_test = test_predictions_GBR[region]\n",
    "        if len(actual_test) == len(predicted_test):  # Ensure the same number of samples\n",
    "            mse_test = mean_squared_error(actual_test, predicted_test)\n",
    "            rmse_test = np.sqrt(mse_test)\n",
    "            mae_test = mean_absolute_error(actual_test, predicted_test)\n",
    "            r2_test = r2_score(actual_test, predicted_test)\n",
    "            n = len(actual_test)\n",
    "            # Number of predictors used in the model (excluding the intercept)\n",
    "            p_test = test_output_data.shape[1] - 1  # Subtract 1 for the intercept\n",
    "            adjusted_r2_test = 1 - (1 - r2_test) * (n - 1) / (n - p_test - 1)\n",
    "            evaluation_metrics_test_GBR[region] = {\"MSE\": mse_test, \"RMSE\": rmse_test, \"MAE\": mae_test, \"R-squared\": r2_test, \"Adjusted R-squared\": adjusted_r2_test}\n",
    "\n",
    "    # Calculate evaluation metrics for train data\n",
    "    for region in train_output_data[\"Region\"].unique():\n",
    "        actual_train = train_output_data[train_output_data[\"Region\"] == region][\"TotalDemand\"].values\n",
    "        predicted_train = train_predictions_GBR[region]\n",
    "        if len(actual_train) == len(predicted_train):  # Ensure the same number of samples\n",
    "            mse_train = mean_squared_error(actual_train, predicted_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            mae_train = mean_absolute_error(actual_train, predicted_train)\n",
    "            r2_train = r2_score(actual_train, predicted_train)\n",
    "            n = len(actual_train)\n",
    "            # Number of predictors used in the model (excluding the intercept)\n",
    "            p_train = train_output_data.shape[1] - 1  # Subtract 1 for the intercept\n",
    "            adjusted_r2_train = 1 - (1 - r2_train) * (n - 1) / (n - p_train - 1)\n",
    "            evaluation_metrics_train_GBR[region] = {\"MSE\": mse_train, \"RMSE\": rmse_train, \"MAE\": mae_train, \"R-squared\": r2_train, \"Adjusted R-squared\": adjusted_r2_train}\n",
    "\n",
    "    return evaluation_metrics_test_GBR, evaluation_metrics_train_GBR\n",
    "\n",
    "def XGBoost(train_input_data, train_output_data):\n",
    "    \n",
    "    XGB_trained = {}  # Dictionary to store trained models for each region\n",
    "    \n",
    "    # Iterate over each region in the training data\n",
    "    for region, dataframe in train_input_data.groupby(\"Region\"):\n",
    "        \n",
    "        # Select the data for the current region\n",
    "        region_train_input = dataframe.drop(columns=[\"Region\"])\n",
    "        region_train_output = train_output_data[train_output_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        \n",
    "        # Initialize and train the XGBoostRegressor model\n",
    "        regressor = XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1)\n",
    "        regressor.fit(region_train_input, region_train_output.values.flatten())\n",
    "        \n",
    "        # Store the trained model in the dictionary\n",
    "        XGB_trained[region] = regressor\n",
    "    \n",
    "    return XGB_trained\n",
    "\n",
    "def get_predictions(trained_models_xgb, test_input_data, test_output_data, train_input_data=None):\n",
    "    \n",
    "    test_predictions_XGB = {}  # Dictionary to store test predictions for each region\n",
    "    train_predictions_XGB = {}  # Dictionary to store train predictions for each region\n",
    "    \n",
    "    # Iterate over each region\n",
    "    for region, model in trained_models_xgb.items():\n",
    "        \n",
    "        # Retrieve the test input and output data for the current region\n",
    "        region_test_input = test_input_data[test_input_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        region_test_output = test_output_data[test_output_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        \n",
    "        # Generate predictions on test data\n",
    "        test_pred = model.predict(region_test_input)\n",
    "        test_predictions_XGB[region] = test_pred\n",
    "        \n",
    "        if train_input_data is not None:\n",
    "            \n",
    "            # If train data is provided, generate predictions on train data as well\n",
    "            region_train_input = train_input_data[train_input_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "            train_pred = model.predict(region_train_input)\n",
    "            train_predictions_XGB[region] = train_pred\n",
    "    \n",
    "    return test_predictions_XGB, train_predictions_XGB\n",
    "\n",
    "def evaluate_model(test_output_data, test_predictions_XGB, train_output_data, train_predictions_XGB):\n",
    "    \n",
    "    # Initialize dictionaries to store evaluation metrics for test and train data\n",
    "    evaluation_metrics_test_XGB = {}\n",
    "    evaluation_metrics_train_XGB = {}\n",
    "\n",
    "    # Calculate evaluation metrics for test data\n",
    "    for region in test_output_data[\"Region\"].unique():\n",
    "        actual_test = test_output_data[test_output_data[\"Region\"] == region][\"TotalDemand\"].values\n",
    "        predicted_test = test_predictions_XGB[region]\n",
    "        if len(actual_test) == len(predicted_test):  # Ensure the same number of samples\n",
    "            mse_test = mean_squared_error(actual_test, predicted_test)\n",
    "            rmse_test = np.sqrt(mse_test)\n",
    "            mae_test = mean_absolute_error(actual_test, predicted_test)\n",
    "            r2_test = r2_score(actual_test, predicted_test)\n",
    "            n = len(actual_test)\n",
    "            # Number of predictors used in the model (excluding the intercept)\n",
    "            p_test = test_output_data.shape[1] - 1  # Subtract 1 for the intercept\n",
    "            adjusted_r2_test = 1 - (1 - r2_test) * (n - 1) / (n - p_test - 1)\n",
    "            evaluation_metrics_test_XGB[region] = {\"MSE\": mse_test, \"RMSE\": rmse_test, \"MAE\": mae_test, \"R-squared\": r2_test, \"Adjusted R-squared\": adjusted_r2_test}\n",
    "\n",
    "    # Calculate evaluation metrics for train data\n",
    "    for region in train_output_data[\"Region\"].unique():\n",
    "        actual_train = train_output_data[train_output_data[\"Region\"] == region][\"TotalDemand\"].values\n",
    "        predicted_train = train_predictions_XGB[region]\n",
    "        if len(actual_train) == len(predicted_train):  # Ensure the same number of samples\n",
    "            mse_train = mean_squared_error(actual_train, predicted_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            mae_train = mean_absolute_error(actual_train, predicted_train)\n",
    "            r2_train = r2_score(actual_train, predicted_train)\n",
    "            n = len(actual_train)\n",
    "            # Number of predictors used in the model (excluding the intercept)\n",
    "            p_train = train_output_data.shape[1] - 1  # Subtract 1 for the intercept\n",
    "            adjusted_r2_train = 1 - (1 - r2_train) * (n - 1) / (n - p_train - 1)\n",
    "            evaluation_metrics_train_XGB[region] = {\"MSE\": mse_train, \"RMSE\": rmse_train, \"MAE\": mae_train, \"R-squared\": r2_train, \"Adjusted R-squared\": adjusted_r2_train}\n",
    "\n",
    "    return evaluation_metrics_test_XGB, evaluation_metrics_train_XGB\n",
    "\n",
    "def LightGBM(train_input_data, train_output_data):\n",
    "    \n",
    "    LGBM_trained = {}  # Dictionary to store trained models for each region\n",
    "    \n",
    "    # Iterate over each region in the training data\n",
    "    for region, dataframe in train_input_data.groupby(\"Region\"):\n",
    "        \n",
    "        # Select the data for the current region\n",
    "        region_train_input = dataframe.drop(columns=[\"Region\"])\n",
    "        region_train_output = train_output_data[train_output_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        \n",
    "        # Initialize and train the LightGBM Regressor model\n",
    "        regressor = LGBMRegressor(random_state=42, verbose=-1)\n",
    "        regressor.fit(region_train_input, region_train_output.values.flatten())\n",
    "        \n",
    "        # Store the trained model in the dictionary\n",
    "        LGBM_trained[region] = regressor\n",
    "    \n",
    "    return LGBM_trained\n",
    "\n",
    "def get_predictions(trained_models_lgbm, test_input_data, test_output_data, train_input_data=None):\n",
    "    \n",
    "    test_predictions_LGBM = {}  # Dictionary to store test predictions for each region\n",
    "    train_predictions_LGBM = {}  # Dictionary to store train predictions for each region\n",
    "    \n",
    "    # Iterate over each region\n",
    "    for region, model in trained_models_lgbm.items():\n",
    "        \n",
    "        # Retrieve the test input and output data for the current region\n",
    "        region_test_input = test_input_data[test_input_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        region_test_output = test_output_data[test_output_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        \n",
    "        # Generate predictions on test data\n",
    "        test_pred = model.predict(region_test_input)\n",
    "        test_predictions_LGBM[region] = test_pred\n",
    "        \n",
    "        if train_input_data is not None:\n",
    "            \n",
    "            # If train data is provided, generate predictions on train data as well\n",
    "            region_train_input = train_input_data[train_input_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "            train_pred = model.predict(region_train_input)\n",
    "            train_predictions_LGBM[region] = train_pred\n",
    "    \n",
    "    return test_predictions_LGBM, train_predictions_LGBM\n",
    "\n",
    "def evaluate_model(test_output_data, test_predictions_LGBM, train_output_data, train_predictions_LGBM):\n",
    "    \n",
    "    # Initialize dictionaries to store evaluation metrics for test and train data\n",
    "    evaluation_metrics_test_LGBM = {}\n",
    "    evaluation_metrics_train_LGBM = {}\n",
    "\n",
    "    # Calculate evaluation metrics for test data\n",
    "    for region in test_output_data[\"Region\"].unique():\n",
    "        actual_test = test_output_data[test_output_data[\"Region\"] == region][\"TotalDemand\"].values\n",
    "        predicted_test = test_predictions_LGBM[region]\n",
    "        if len(actual_test) == len(predicted_test):  # Ensure the same number of samples\n",
    "            mse_test = mean_squared_error(actual_test, predicted_test)\n",
    "            rmse_test = np.sqrt(mse_test)\n",
    "            mae_test = mean_absolute_error(actual_test, predicted_test)\n",
    "            r2_test = r2_score(actual_test, predicted_test)\n",
    "            n = len(actual_test)\n",
    "            # Number of predictors used in the model (excluding the intercept)\n",
    "            p_test = test_output_data.shape[1] - 1  # Subtract 1 for the intercept\n",
    "            adjusted_r2_test = 1 - (1 - r2_test) * (n - 1) / (n - p_test - 1)\n",
    "            evaluation_metrics_test_LGBM[region] = {\"MSE\": mse_test, \"RMSE\": rmse_test, \"MAE\": mae_test, \"R-squared\": r2_test, \"Adjusted R-squared\": adjusted_r2_test}\n",
    "\n",
    "    # Calculate evaluation metrics for train data\n",
    "    for region in train_output_data[\"Region\"].unique():\n",
    "        actual_train = train_output_data[train_output_data[\"Region\"] == region][\"TotalDemand\"].values\n",
    "        predicted_train = train_predictions_LGBM[region]\n",
    "        if len(actual_train) == len(predicted_train):  # Ensure the same number of samples\n",
    "            mse_train = mean_squared_error(actual_train, predicted_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            mae_train = mean_absolute_error(actual_train, predicted_train)\n",
    "            r2_train = r2_score(actual_train, predicted_train)\n",
    "            n = len(actual_train)\n",
    "            # Number of predictors used in the model (excluding the intercept)\n",
    "            p_train = train_output_data.shape[1] - 1  # Subtract 1 for the intercept\n",
    "            adjusted_r2_train = 1 - (1 - r2_train) * (n - 1) / (n - p_train - 1)\n",
    "            evaluation_metrics_train_LGBM[region] = {\"MSE\": mse_train, \"RMSE\": rmse_train, \"MAE\": mae_train, \"R-squared\": r2_train, \"Adjusted R-squared\": adjusted_r2_train}\n",
    "\n",
    "    return evaluation_metrics_test_LGBM, evaluation_metrics_train_LGBM\n",
    "\n",
    "def CatBoost(train_input_data, train_output_data):\n",
    "    \n",
    "    CBR_trained = {}  # Dictionary to store trained models for each region\n",
    "    \n",
    "    # Iterate over each region in the training data\n",
    "    for region, dataframe in train_input_data.groupby(\"Region\"):\n",
    "        \n",
    "        # Select the data for the current region\n",
    "        region_train_input = dataframe.drop(columns=[\"Region\"])\n",
    "        region_train_output = train_output_data[train_output_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        \n",
    "        # Initialize and train the CatBoostRegressor model\n",
    "        regressor = CatBoostRegressor(random_state=42, silent=True)\n",
    "        regressor.fit(region_train_input, region_train_output.values.flatten())\n",
    "        \n",
    "        # Store the trained model in the dictionary\n",
    "        CBR_trained[region] = regressor\n",
    "    \n",
    "    return CBR_trained\n",
    "\n",
    "def get_predictions(trained_models_cbr, test_input_data, test_output_data, train_input_data=None):\n",
    "    \n",
    "    test_predictions_CBR = {}  # Dictionary to store test predictions for each region\n",
    "    train_predictions_CBR = {}  # Dictionary to store train predictions for each region\n",
    "    \n",
    "    # Iterate over each region\n",
    "    for region, model in trained_models_cbr.items():\n",
    "        \n",
    "        # Retrieve the test input and output data for the current region\n",
    "        region_test_input = test_input_data[test_input_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        region_test_output = test_output_data[test_output_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        \n",
    "        # Generate predictions on test data\n",
    "        test_pred = model.predict(region_test_input)\n",
    "        test_predictions_CBR[region] = test_pred\n",
    "        \n",
    "        if train_input_data is not None:\n",
    "            \n",
    "            # If train data is provided, generate predictions on train data as well\n",
    "            region_train_input = train_input_data[train_input_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "            train_pred = model.predict(region_train_input)\n",
    "            train_predictions_CBR[region] = train_pred\n",
    "    \n",
    "    return test_predictions_CBR, train_predictions_CBR\n",
    "\n",
    "def evaluate_model(test_output_data, test_predictions_CBR, train_output_data, train_predictions_CBR):\n",
    "    \n",
    "    # Initialize dictionaries to store evaluation metrics for test and train data\n",
    "    evaluation_metrics_test_CBR = {}\n",
    "    evaluation_metrics_train_CBR = {}\n",
    "\n",
    "    # Calculate evaluation metrics for test data\n",
    "    for region in test_output_data[\"Region\"].unique():\n",
    "        actual_test = test_output_data[test_output_data[\"Region\"] == region][\"TotalDemand\"].values\n",
    "        predicted_test = test_predictions_CBR[region]\n",
    "        if len(actual_test) == len(predicted_test):  # Ensure the same number of samples\n",
    "            mse_test = mean_squared_error(actual_test, predicted_test)\n",
    "            rmse_test = np.sqrt(mse_test)\n",
    "            mae_test = mean_absolute_error(actual_test, predicted_test)\n",
    "            r2_test = r2_score(actual_test, predicted_test)\n",
    "            n = len(actual_test)\n",
    "            # Number of predictors used in the model (excluding the intercept)\n",
    "            p_test = test_output_data.shape[1] - 1  # Subtract 1 for the intercept\n",
    "            adjusted_r2_test = 1 - (1 - r2_test) * (n - 1) / (n - p_test - 1)\n",
    "            evaluation_metrics_test_CBR[region] = {\"MSE\": mse_test, \"RMSE\": rmse_test, \"MAE\": mae_test, \"R-squared\": r2_test, \"Adjusted R-squared\": adjusted_r2_test}\n",
    "\n",
    "    # Calculate evaluation metrics for train data\n",
    "    for region in train_output_data[\"Region\"].unique():\n",
    "        actual_train = train_output_data[train_output_data[\"Region\"] == region][\"TotalDemand\"].values\n",
    "        predicted_train = train_predictions_CBR[region]\n",
    "        if len(actual_train) == len(predicted_train):  # Ensure the same number of samples\n",
    "            mse_train = mean_squared_error(actual_train, predicted_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            mae_train = mean_absolute_error(actual_train, predicted_train)\n",
    "            r2_train = r2_score(actual_train, predicted_train)\n",
    "            n = len(actual_train)\n",
    "            # Number of predictors used in the model (excluding the intercept)\n",
    "            p_train = train_output_data.shape[1] - 1  # Subtract 1 for the intercept\n",
    "            adjusted_r2_train = 1 - (1 - r2_train) * (n - 1) / (n - p_train - 1)\n",
    "            evaluation_metrics_train_CBR[region] = {\"MSE\": mse_train, \"RMSE\": rmse_train, \"MAE\": mae_train, \"R-squared\": r2_train, \"Adjusted R-squared\": adjusted_r2_train}\n",
    "\n",
    "    return evaluation_metrics_test_CBR, evaluation_metrics_train_CBR\n",
    "\n",
    "def ADABoost(train_input_data, train_output_data):\n",
    "    \n",
    "    ADAB_trained = {}  # Dictionary to store trained models for each region\n",
    "    \n",
    "    # Iterate over each region in the training data\n",
    "    for region, dataframe in train_input_data.groupby(\"Region\"):\n",
    "        \n",
    "        # Select the data for the current region\n",
    "        region_train_input = dataframe.drop(columns=[\"Region\"])\n",
    "        region_train_output = train_output_data[train_output_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        \n",
    "        # Initialize and train the ADABoost Regressor model\n",
    "        regressor = AdaBoostRegressor(random_state=42)\n",
    "        regressor.fit(region_train_input, region_train_output.values.flatten())\n",
    "        \n",
    "        # Store the trained model in the dictionary\n",
    "        ADAB_trained[region] = regressor\n",
    "    \n",
    "    return ADAB_trained\n",
    "\n",
    "def get_predictions(trained_models_adab, test_input_data, test_output_data, train_input_data=None):\n",
    "    \n",
    "    test_predictions_ADAB = {}  # Dictionary to store test predictions for each region\n",
    "    train_predictions_ADAB = {}  # Dictionary to store train predictions for each region\n",
    "    \n",
    "    # Iterate over each region\n",
    "    for region, model in trained_models_adab.items():\n",
    "        \n",
    "        # Retrieve the test input and output data for the current region\n",
    "        region_test_input = test_input_data[test_input_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        region_test_output = test_output_data[test_output_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        \n",
    "        # Generate predictions on test data\n",
    "        test_pred = model.predict(region_test_input)\n",
    "        test_predictions_ADAB[region] = test_pred\n",
    "        \n",
    "        if train_input_data is not None:\n",
    "            \n",
    "            # If train data is provided, generate predictions on train data as well\n",
    "            region_train_input = train_input_data[train_input_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "            train_pred = model.predict(region_train_input)\n",
    "            train_predictions_ADAB[region] = train_pred\n",
    "    \n",
    "    return test_predictions_ADAB, train_predictions_ADAB\n",
    "\n",
    "def evaluate_model(test_output_data, test_predictions_ADAB, train_output_data, train_predictions_ADAB):\n",
    "    \n",
    "    # Initialize dictionaries to store evaluation metrics for test and train data\n",
    "    evaluation_metrics_test_ADAB = {}\n",
    "    evaluation_metrics_train_ADAB = {}\n",
    "\n",
    "    # Calculate evaluation metrics for test data\n",
    "    for region in test_output_data[\"Region\"].unique():\n",
    "        actual_test = test_output_data[test_output_data[\"Region\"] == region][\"TotalDemand\"].values\n",
    "        predicted_test = test_predictions_ADAB[region]\n",
    "        if len(actual_test) == len(predicted_test):  # Ensure the same number of samples\n",
    "            mse_test = mean_squared_error(actual_test, predicted_test)\n",
    "            rmse_test = np.sqrt(mse_test)\n",
    "            mae_test = mean_absolute_error(actual_test, predicted_test)\n",
    "            r2_test = r2_score(actual_test, predicted_test)\n",
    "            n = len(actual_test)\n",
    "            # Number of predictors used in the model (excluding the intercept)\n",
    "            p_test = test_output_data.shape[1] - 1  # Subtract 1 for the intercept\n",
    "            adjusted_r2_test = 1 - (1 - r2_test) * (n - 1) / (n - p_test - 1)\n",
    "            evaluation_metrics_test_ADAB[region] = {\"MSE\": mse_test, \"RMSE\": rmse_test, \"MAE\": mae_test, \"R-squared\": r2_test, \"Adjusted R-squared\": adjusted_r2_test}\n",
    "\n",
    "    # Calculate evaluation metrics for train data\n",
    "    for region in train_output_data[\"Region\"].unique():\n",
    "        actual_train = train_output_data[train_output_data[\"Region\"] == region][\"TotalDemand\"].values\n",
    "        predicted_train = train_predictions_ADAB[region]\n",
    "        if len(actual_train) == len(predicted_train):  # Ensure the same number of samples\n",
    "            mse_train = mean_squared_error(actual_train, predicted_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            mae_train = mean_absolute_error(actual_train, predicted_train)\n",
    "            r2_train = r2_score(actual_train, predicted_train)\n",
    "            n = len(actual_train)\n",
    "            # Number of predictors used in the model (excluding the intercept)\n",
    "            p_train = train_output_data.shape[1] - 1  # Subtract 1 for the intercept\n",
    "            adjusted_r2_train = 1 - (1 - r2_train) * (n - 1) / (n - p_train - 1)\n",
    "            evaluation_metrics_train_ADAB[region] = {\"MSE\": mse_train, \"RMSE\": rmse_train, \"MAE\": mae_train, \"R-squared\": r2_train, \"Adjusted R-squared\": adjusted_r2_train}\n",
    "\n",
    "    return evaluation_metrics_test_ADAB, evaluation_metrics_train_ADAB\n",
    "\n",
    "def Stacked_Ensemble_Combine_Predictions(trained_models_xgb, trained_models_lgbm, test_input_data):\n",
    "    \n",
    "    # Dictionary to store test predictions for each region\n",
    "    test_predictions_SE = {}  \n",
    "    \n",
    "    # Iterate over each region\n",
    "    for region in trained_models_xgb.keys():\n",
    "        # Retrieve the test input data for the current region\n",
    "        region_test_input = test_input_data[test_input_data[\"Region\"] == region].drop(columns=[\"Region\"])\n",
    "        \n",
    "        # Generate predictions on test data using XGBoost model\n",
    "        xgb_pred = trained_models_xgb[region].predict(region_test_input)\n",
    "        \n",
    "        # Generate predictions on test data using LightGBM model\n",
    "        lgbm_pred = trained_models_lgbm[region].predict(region_test_input)\n",
    "        \n",
    "        # Combine predictions using a Random Forest regression meta-model\n",
    "        ensemble_features = np.vstack((xgb_pred, lgbm_pred)).T\n",
    "        meta_model = RandomForestRegressor()\n",
    "        meta_model.fit(ensemble_features, xgb_pred)  # Using XGBoost predictions for training\n",
    "        \n",
    "        # Make predictions on test data\n",
    "        ensemble_predictions = meta_model.predict(ensemble_features)\n",
    "        test_predictions_SE[region] = ensemble_predictions\n",
    "        \n",
    "    return test_predictions_SE\n",
    "\n",
    "def adjusted_r_model_comparison():\n",
    "    \n",
    "    # Set style\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Evaluation metrics data (R-squared for each model and region)\n",
    "    regions = ['QLD', 'SA', 'TAS', 'VIC', 'NSW']\n",
    "    models = ['ExtraTrees', 'Gradient Boosting', 'XGBoost', 'LightGBM', 'CatBoost', 'ADABoost', 'Stacked Ensemble']\n",
    "    adj_r_squared_values = {\n",
    "        'ExtraTrees': [0.7941652793981316, 0.39201131007634915, 0.7220470192873729, 0.4455541543409408, 0.8117077458148688],\n",
    "        'Gradient Boosting': [0.7820569481377042, 0.3103845806089077, 0.7102251931692325, 0.37191294670349295, 0.7677917757114525],\n",
    "        'XGBoost': [0.8234800188620719, 0.30479881442366774, 0.7178666881584719, 0.3655267180611894, 0.812876314028925],\n",
    "        'LightGBM': [0.8268776836153175, 0.3851347340528738, 0.7411651844485945, 0.40101964061509543, 0.818068598082448],\n",
    "        'CatBoost': [0.8404561562419313, 0.3720477987436638, 0.7339870551721315, 0.3807099585775112, 0.8279404458857167],\n",
    "        'ADABoost': [0.6910033546058161, 0.24432329542299447, 0.6592185598678055, 0.22428957184409692, 0.5415415370185472],\n",
    "        'Stacked Ensemble': [0.8234707592766461, 0.3047778966837662, 0.7178573604107441, 0.36553323830187334, 0.8128632983359723]\n",
    "    }\n",
    "\n",
    "    # Set the width of the bars\n",
    "    bar_width = 0.16\n",
    "\n",
    "    # Set the x locations for the groups\n",
    "    x = np.arange(len(models))\n",
    "\n",
    "    # Define a wider range of distinct colors for regions\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(17, 8))\n",
    "\n",
    "    for i, region in enumerate(regions):\n",
    "        adj_r_squared_region = [adj_r_squared_values[model][i] for model in models]\n",
    "        plt.bar(x + (i - 2) * bar_width, adj_r_squared_region, width=bar_width, label=region, color=colors[i])\n",
    "\n",
    "    plt.xlabel('Models', fontsize=12, color='black')\n",
    "    plt.ylabel('Adjusted R-squared value', fontsize=12, color='black')\n",
    "    plt.title('Adjusted R-squared value Comparison for Different Models among Regions', fontweight=\"bold\", fontsize=14, color='black')\n",
    "    plt.xticks(x, models, color='black')\n",
    "    plt.grid(True)\n",
    "    plt.legend(title='Regions', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
